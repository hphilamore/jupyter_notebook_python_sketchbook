Title,email,kwords,prog,title,desc,n_students,uni,programme,second_supervisor_name,University,Student name if co-created,co-created_project
Arthur Richards,arthur.richards@bristol.ac.uk,Drones; Autonomy; Safety,"MSc Aerial Robotics, MSc Robotics",Safely Automating Drone Handling,"Extensive work has been done to automate the flight of drones â€“ but before and after flight there are extensive periods of initialization and handling that are almost entirely manual.  Activities include checking and fitting batteries, starting software, verifying connectivity and navigation, and visual inspection.  These activities can be hazardous: you really donâ€™t want a drone to spin up while youâ€™re holding it.  Some of these activities are naturally suited to humans, while others could be automated.  This project will adopt a hybrid approach to build a semi-autonomous drone handling station in the flying arena at BRL.  The overall goal will be to support a human operator in getting drones â€œturned aroundâ€ù and back ready for flight efficiently and safely.  Ideas from smart manufacturing will be leveraged to identify a smooth and easily supervised process flow.  The project is suitable for students with good software and system integration skills and preferably some electronics. ",1,UoB,"[""MSc Aerial Robotics"",""MSc Robotics""]",Hirad Goudarzi,UoB,,
Arthur Richards,arthur.richards@bristol.ac.uk,Control; Vision; Cameras,"MSc Aerial Robotics, MSc Robotics",Automated filming of indoor drone experiments ,"Many publications venues expect high quality media in order for a paper to be accepted. This is especially needed in single and multi-drone experimentation where video has a lot of value. This project aims to look at the design and implementation of an automated filming system for the Bristol Robotics Laboratory Flight Arena. This includes questions such as the optimal design of a camera setup, the automated control of a camera rig in order to capture video of interest, allocation of objects to cameras, the integration of the setup into the existing flight arena systems and the user interaction. Mixed vision and tracking processing for automated editing could also be considered, perhaps even with a machine learning approach to footage selection.  This project is suitable for candidates with backgrounds in electronics and software with interests in robotics for filming and will involve development within the BRL. ",1,UoB,"[""MSc Aerial Robotics"",""MSc Robotics""]",Mickey Li,UoB,,
Arthur Richards,arthur.richards@bristol.ac.uk,Drones; Autonomy; Multi-agent,"MSc Aerial Robotics, MSc Robotics",Self-Replenishing Drone Team,"For applications involving monitoring, it is important for system downtime to be minimised. This is a challenge for a team of drones as any single drone is limited by short battery life and other factors. One possible method is to have a â€˜spare' drone which is available to take over the task of a working drone, therefore freeing the drone to have its battery replaced or undergo maintenance. But there are questions as to how the spare knows to attempt a task handover, what happens if multiple vehicles fail and so on.  Therefore, this project aims to look at planning strategies which can minimise the mission downtime when using a team of drones for a monitoring scenario. Interested students should have sound scientific programming skills and either know, or be willing to pick up python, and also have willingness to learn about and evaluate different task allocation/mission planning methods. If the project goes well, and the candidate has strong programming skill, there is also the opportunity to fly the method on real drones at the Bristol Robotics Laboratory Flight Arena.  ",1,UoB,"[""MSc Aerial Robotics""]",Mickey Li,UoB,,
Arthur Richards,arthur.richards@bristol.ac.uk,Drones; Autonomy; Multi-agent,"MSc Aerial Robotics, MSc Robotics",Distributed Heartbeat based Multi-UAV Health Monitoring using Bluetooth ,"Communication is a key aspect of practical multi-uav teaming, not only for transferring data, but for determining the health of fellow teammates. UAVs are fairly failure prone, and knowing the health status of teammates enables agents to decide whether they should change their plans in order to complete their assigned mission. This project aims to apply a new synchronous flooding communications protocol known as Atomic (https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8726297) over Bluetooth to implement a heartbeat based health monitoring system for multiple UAVs doing a task. This will require designing both the communication and implementing a distributed decision-making protocol for drones.  Interested students should ideally have some experience with embedded hardware and programming in C/C++ as well as willingness to learn about and evaluate different distributed decision-making protocols. The project will be based in the Bristol Robotics Laboratory Flight Arena and, if things go well, will include the opportunity to fly real drones. ",1,UoB,"[""MSc Aerial Robotics""]",Mickey Li; Hirad Goudarzi,UoB,,
Arthur Richards,arthur.richards@bristol.ac.uk,Drones; Safety; Traffic Management,"MSc Aerial Robotics, MSc Robotics",Drone traffic management in urban environments ,"A previous project validated the concept of a â€œring roadâ€ù for drones, where reduced ground risk enabled higher speeds, and offering both faster and safer transit of populated areas.  This project will seek to generalize the work so far.  Several directions are possible, including an abstract analysis looking at simple geometric arrangements of ring roads and parametric studies covering speed ratios and demand densities.  Alternatively, a more concrete approach could explore the impact of different detailed designs on network performance, looking at different ring road routing options around Bristol or another candidate city.  Routing is partly a question of policy: is it â€œacceptableâ€ù to route drones over roads, railways, rivers or rooftops?  However, that policy needs to be informed by studies of the impact of those different choices.  This project is entirely software-based and is suitable for students with good scientific programming skills, especially Python but possibly Matlab. ",1,UoB,"[""MSc Aerial Robotics""]",Hirad Goudarzi,UoB,,
Edmund Hunt,edmund.hunt@bristol.ac.uk,"swarm robotics, minimal control, environmental monitoring","MSc BioRobotics, MSc Robotics",MCMC methods for stochastic robot swarm control,"The philosophy of swarm robotics is that large numbers of simple agents can achieve significant tasks, overcoming simplicity through strength in numbers. Such a task could be exploring an environment to find concentrated patches of pollution, for example. Markov chain Monte Carlo (MCMC) methods are a class of algorithms used to sample from probability distributions. A â€˜walkerâ€™ moves through the distribution and obtains samples as it goes. Given enough time, these samples resemble the target distribution. We have compared this movement [1] to the movement of real animals, ants, which are a prime source of inspiration for swarm robotics. Effective MCMC methods tend to combine randomness (stochasticity) in walker movement with some form of gradient following (i.e. tending to prefer movement toward higher probability).  In this project, we will consider whether MCMC methods can be used to inspire movement controllers for minimal, stochastic robot swarms. We will use the CoppeliaSim simulator (https://www.coppeliarobotics.com/).    [1] Baddeley, R. J., Franks, N. R., & Hunt, E. R. (2019). Optimal foraging and the information theory of gambling. Journal of The Royal Society Interface, 16(157), 20190162.",1,UoB,,,,,
Dandan Zhang,ye21623@bristol.ac.uk,"Robot learning ( Machine Learning and Deep Learning for Robotic Manipulation/Computer Vision), Teleoperation, Tactile Robotics, Human-Robot Shared Control, Human-Robot Interaction, Multi-Sensor Fusion","MSc BioRobotics, MSc Robotics",,,,UoB,,,,,
Helmut Hauser,helmut.hauser@bristol.ac.uk,"morphological computation, physical reservoir computing, soft robotics","MSc BioRobotics, MSc Robotics",Improving Physical Reservoir Computing ,"Reservoir computing is a machine learning technique that allows us to learn to emulate complex nonlinear dynamical systems with simple linear regression. The key idea is to have a  so-called reservoir, which is itself a complex, nonlinear dynamical system that we simply exploit as a computational resource. While traditionally the reservoirs are made up of abstract nonlinear systems, in recent years, numerous research groups have shown that such a reservoir can also be realised as real physical bodies ranging from setups using nonlinear effects in lasers, capacity networks and mechanical structures (e.g., parts of a robot). In the context of robotics, this means the soft body of the robot can be exploited for computational tasks [1][2], including for control and sensing. This is typically referred to as physical reservoir computing [3].   This project explores how the computational power can be extended by including special types of dynamics in the robto body, e.g. bifurcation, bi-stability or hysteresis. The project allows for a number of different approaches (simulation, real robots, the use of machine learning, etc.) and details can be discussed with the supervisor.  Requirements: understanding of nonlinear dynamical systems, Python programming   [1] Hauser, H.; Ijspeert, A.; FÃ_chslin, R.; Pfeifer, R. & Maass, W.""Towards a theoretical foundation for morphological computation with compliant bodies""Biological Cybernetics, Springer Berlin / Heidelberg, 2011, 105, 355-370http://www.springerlink.com/content/j236312507300638/[2]  Hauser,   [2] H.; Ijspeert, A.; FÃ_chslin, R.; Pfeifer, R. & Maass, W.""The role of feedback in morphological computation with compliant bodies""Biological Cybernetics, Springer Berlin / Heidelberg, 2012, 106, 595-613http://www.springerlink.com/content/d54t39qh28561271/  [1] 1. Hauser, H. Physical Reservoir Computing in Robotics. Nat. Comput. Ser. 169â€“190 (2021). doi:10.1007/978-981-13-1687-6_8",2,UoB,"[""MSc Robotics"",""MSc Bio-Robotics""]",,UoB,,
Hermes Gadelha,hermes.gadelha@bristol.ac.uk,"Soft-robotics of mÃ_crobes, self locomotion, artificial cilia","MSc BioRobotics, MSc Robotics",Soft-robotics of the sperm tail ,"The human sperm tail in an intelligent soft material composed by many interacting fibres connected by elastic springs. This intelligent structure is able to share mechanical information across long distances instantaneously and adapt under different loading conditions. Most curiously,  under deformation of one part of the tail, the other part can bend in the opposite direction, something known as the Ã¢â‚¬Å“counterbendÃ¢â‚¬Âù phenomenon. This project aims to take this biological architecture to design the next generation of articulated soft robots. The student will build a soft-robotic arm by just using strips of a piece of paper, from which bending experiments will be conducted. Images of the different deformations will be compared with a simulational tool of this system (provided) so that the viability of the design may be assessed. This project is based on the current need for cheap and intelligent materials that are able to communicate mechanical information and self-adapt under  different situations.",1,UoB,"[""MSc Bio-Robotics"",""MSc Robotics""]",,,,
Hermes Gadelha,hermes.gadelha@bristol.ac.uk,"Soft-robotics of mÃ_crobes, self locomotion, artificial cilia","MSc BioRobotics, MSc Robotics",Soft-robotics spontaneous travelling waves locomotor,"Molecular motors are force generators which can produce mechanicaloscillations at the cellular scale and play a central role in muscle contractionand cell motility. Insect fibrilar muscles of wasps and bees are known to exhibita wing thrust which is asynchronous to the activating nervous impulses.Skinned skeletal and cardiac muscle fibers have also been shown to exhibitspontaneous oscillations in vitro under various conditions. Other non-muscularexamples are the periodic motion of cilia and flagella used for cell motility andthe amplification of weak stimuli via oscillatory instabilities of mechanosensoryhair bundles.Early models proposed to understand such systems weregrounded on experimental evidences of muscle contraction and weresubsequently generalized to the study of eukaryotic flagella. In this project, we will  build artificial generic soft-robotic model for the collective dynamics of molecular motors which generates spontaneous oscillations. ",1,UoB,,,,,
Hermes Gadelha,hermes.gadelha@bristol.ac.uk,"Soft-robotics of mÃ_crobes, self locomotion, artificial cilia","MSc BioRobotics, MSc Robotics",Microorganism inspired robots Bio-SoftRobotics,"The idea is to construct and macroscopic bio-inspired robot that is able to swim via travelling waves of contractions along a flexible tail. Other micrrorganisms may be used as inspiration, such as robo-bacterium, robo-paramelcium, point-force robots, flexible-sheet robot, 3D printed sperm flagellum, polymorphic bacterium flagellum, Turing self-organised robots.",1,UoB,,,,,
Hermes Gadelha,hermes.gadelha@bristol.ac.uk,"Soft-robotics of mÃ_crobes, self locomotion, artificial cilia","MSc BioRobotics, MSc Robotics",Worm-like robots,"This project aims to devise a robot capable of moving in porous media. It is a challenging task to achive locomotion or propulsion in porous environment, for example sand. This project draws inspiration from warms that are capable of efficintly moving in complex environment. ",1,UoB,,,,,
Hermes Gadelha,hermes.gadelha@bristol.ac.uk,"Soft-robotics of mÃ_crobes, self locomotion, artificial cilia","MSc BioRobotics, MSc Robotics",Amphibious soft-robot,Terrestrial organisms evolved by migrating from its quatic form to a terrestrial form. Very little is known about how this actually took place over millions of years. The idea of this project is to devise soft-robots capable of moving in both aquatic and terrestrial environments.,1,UoB,,,,,
Hermes Gadelha,hermes.gadelha@bristol.ac.uk,"Soft-robotics of mÃ_crobes, self locomotion, artificial cilia","MSc BioRobotics, MSc Robotics",Environmental control of microswarms,"Microorganisms swim at the microscale in all random directions. It is a difficult task to control the swarming motion without externally interfinging with their motion in a dirrect manner. This project builds on recent  development that allows to ""print"" light patterns at the microscale. This allows local changes in temperature and viscosity of the environment, as well as guide phototatic microorganisms (micro-swimmers able to swim toward light), that in turn could be used to guide and achieve high-levels of control of a swarming population of micro-swimmers.",1,UoB,,,,,
Hermes Gadelha,hermes.gadelha@bristol.ac.uk,"Soft-robotics of mÃ_crobes, self locomotion, artificial cilia","MSc BioRobotics, MSc Robotics",Modelling lateral sensory lines in fish,"Most of fish are capable of sensing pressure waves in the fluid environment via specialised lateral sensory lines. Recent development in Hauert laboratory includes the first design of the first artificial sensory lines for robotic swimming. This project aims to tackle this problem using mathematical modeling and simulation of the predicted behaviour of the sensory lines, build as flexible filaments whiare are able to bend and buckle according to the external forces in the fluid environment. This is an interdiciplinary project aimed at predicting the mechanical behaviour from the sensory lines for later comparison with the experimntal emasurements of the device. ",1,UoB,,,,,
Hermes Gadelha,hermes.gadelha@bristol.ac.uk,"Soft-robotics of mÃ_crobes, self locomotion, artificial cilia","MSc BioRobotics, MSc Robotics",Artificial motile cilia ,"Cilia is a motile cell apendage with a whip-like structure that beats in a coordinated fhashion to drive fluid and propel microorganisms. In the lungs, cilia is responsible for clearing our airways from mucus. This project aims to fabricate robotic cilia capable of driving fluid in a coordinated fashion.",1,UoB,"[""MSc Robotics"",""MSc Bio-Robotics""]",,,,
Hermes Gadelha,hermes.gadelha@bristol.ac.uk,"Soft-robotics of mÃ_crobes, self locomotion, artificial cilia","MSc BioRobotics, MSc Robotics",The artificial soft-robotic sperm flagellum,"The human sperm tail in an intelligent soft material composed by many interacting fibres connected by elastic springs. This intelligent structure is able to share mechanical information across long distances instantaneously and adapt under different loading conditions. Most curiously, under deformation of one part of the tail, the other part can bend in the opposite direction, something known as the counterbend phenomenon. This project aims to take this biological architecture to design the next generation of articulated soft robots. The student will build a soft-robotic sperm tail by just using strips of a piece of paper, from which bending experiments will be conducted. Images of the different deformations will be compared with a simulations so that the viability of the design may be assessed. This project is based on the current need for cheap and intelligent materials that are able to communicate mechanical information and self-adapt under different situations. See for example: https://edition.cnn.com/2020/07/31/health/sperm-swimming-movement-wellness/index.html",1,UoB,,,,,
Hermes Gadelha,hermes.gadelha@bristol.ac.uk,"Soft-robotics of mÃ_crobes, self locomotion, artificial cilia","MSc BioRobotics, MSc Robotics",Microorganism inspired artificial swimmers,"The idea is to construct and macroscopic bio-inspired robot that is able to swim via travelling waves of contractions along a flexible tail. Other micrrorganisms may be used as inspiration, such as robo-bacterium, robo-paramelcium, point-force robots, flexible-sheet robot, 3D printed sperm flagellum, polymorphic bacterium flagellum. The most innovative part of this project is that few ""point forces"" can be used to mimic the fluid motion of complex moving objects, so one can avoid  the construction of  complex structure of the microorganisms.  See for example: https://edition.cnn.com/2020/07/31/health/sperm-swimming-movement-wellness/index.html",1,UoB,,,,,
Chanelle Lee,c.l.lee@bristol.ac.uk,"multi-agent systems, decision making, swarm robotics","MSc BioRobotics, MSc Robotics",Resiliency to Byzantine agents in the best-of-n decision problem,"Swarm robotic systems are often claimed to be highly fault-tolerant; however, few works have considered their resiliency in the presence of Byzantine agents, i.e. agents with benign faulty or malicious behaviours. In consensus achievement problems, resilience becomes a trade-off between effectively exploiting information provided by reliable agents while mitigating the influence of that from faulty or malicious agents.  In this project, we consider the best-of-n decision problem wherein the swarm of agents must choose between n options each with an associated quality which is received as feedback by members of the swarm. We will use a probabilistic model of opinion propagation and agent-based simulations to tackle two questions: -	What limits should be imposed on agent interactions when there are Byzantine agents? -	How can we identify faulty or malicious agents in the system? This project would suit a student looking for a balance of theoretical work and programming simulations. It will involve writing large scale simulations in python (or Matlab) as well as developing theoretical ideas about Bayesian updating in this context. Extensions to the project could include using more realistic robotic simulation software such as V-rep. The findings of this project will be useful for improving the security of swarm robotic systems and thus of interest to swarm robotic engineers and those with a strong interest in reliable multi-agent systems e.g. Thales.",1,UoB,,,UoB,,
Shane Windsor,shane.windsor@bristol.ac.uk,"bio-inspiration, unmanned air vehicles, bird flight, trustworthy autonomous systems",MSc Aerial Robotics,Morphing wing UAV development,The way birds morph their wings to achieve manoeuvrable yet efficient flight offers inspiration for alternative designs for fixed wing uncrewed air vehicles (UAVs). This project will look at designing and flight-testing UAVs with morphing wings based on research we are conducting on how birds of prey use wing morphing for flight control.,1,UoB,"[""MSc Aerial Robotics""]",,UoB,,
Tom Richardson,thomas.richardson@bristol.ac.uk,"Drones systems, applications, control & sensing.",MSc Aerial Robotics,Multimodal robotic design for conservation applications,Design a robot that can both drive/crawl on the ground as well as fly - without too much compromise in either mode. Research areas of interest are in the design optimisation and the control of the vehicle (my background is in control theory),1,UoB,,,,,
Lucia Marucci,lucia.marucci@bristol.ac.uk,"microfluidics, feedback control, mammalian cells ",MSc BioRobotics,,,,UoB,,,,,
Sebastian East,sebastian.east@bristol.ac.uk,"Optimal Control, Model Predictive Control, Machine Learning-based Control","MSc Aerial Robotics, MSc BioRobotics, MSc Robotics",Neural Model Predictive Control,"This project is an investigation into the use of neural networks for synthesising model predictive control policies. There are two possible directions to take with this project: either a theoretical approach that considers stability and constraint satisfaction of the learned controller (would be suitable for a student with a strong background in mathematics, including real analysis), or an applied approach looking at the experimental implementation of neural MPC (in either hardware or simulation).",1,UoB,"[""MSc Aerial Robotics"",""MSc Robotics""]",,UoB,,
Sabine Hauert,sabine.hauert@bristol.ac.uk,"Swarm robotics, swarms for intralogistics, artificial evolution of swarm behaviours, explainable swarms, safe swarms, trustworthy swarms, swarming nano-micro systems for biomedical applications, environmental swarms.","MSc BioRobotics, MSc Robotics",AI-driven design of swarming microsystems,"This project aims to do online evolution of behaviour trees for the automatic design of controllers for swarming micro-agents (bacteria, cancer cells, microparticles). It will be implemented and tested on our DOME device, which includes a DLP projector, and camera, all controlled using Raspberry Pis.",1,UoB,,,,,
Sabine Hauert,sabine.hauert@bristol.ac.uk,"Swarm robotics, swarms for intralogistics, artificial evolution of swarm behaviours, explainable swarms, safe swarms, trustworthy swarms, swarming nano-micro systems for biomedical applications, environmental swarms.","MSc BioRobotics, MSc Robotics",Robot swarms for warehouse stacking,"To increase efficiency, more and more warehouses are automated using mobile robots (mostly centralized systems). To make best use of the space, robots will need to stack items. This project looks at how a swarm of robots with robot arms can grip, transport, and stack objects in a warehouse. Experiments will be done in simulation and on the Industrial Swarm Testbed.",1,UoB,,,,,
Sabine Hauert,sabine.hauert@bristol.ac.uk,"Swarm robotics, swarms for intralogistics, artificial evolution of swarm behaviours, explainable swarms, safe swarms, trustworthy swarms, swarming nano-micro systems for biomedical applications, environmental swarms.","MSc BioRobotics, MSc Robotics",Swarms for moon exploration,"This project researches the use of swarm robotics for the exploration of moons/planets. The swarm would map and explore areas in space where it could have a number of different applications, including the detection of water and other signs of life. There are a variety of different robots which could be used in the swarm, including rovers and hopping robots. The project would use simulations to explore and analyze the behavior of the swarm and the potential applications in space.",1,UoB,,,,,
Sabine Hauert,sabine.hauert@bristol.ac.uk,"Swarm robotics, swarms for intralogistics, artificial evolution of swarm behaviours, explainable swarms, safe swarms, trustworthy swarms, swarming nano-micro systems for biomedical applications, environmental swarms.","MSc BioRobotics, MSc Robotics",Solution to the optimal nutrition problem using an evolutionary algorithm,Meal plans for optimal nutrition have to satisfy multiple constraints and maximise multiple objectives. The project aims at developing an evolutionary algorithm to solve this problem within reasonable time and dynamically adapt the solution to manual changes to the plan.,1,UoB,,,,,
Sabine Hauert,sabine.hauert@bristol.ac.uk,"Swarm robotics, swarms for intralogistics, artificial evolution of swarm behaviours, explainable swarms, safe swarms, trustworthy swarms, swarming nano-micro systems for biomedical applications, environmental swarms.","MSc BioRobotics, MSc Robotics",Robot swarms to monitor Basking Sharks,"Basking sharks have amazing filter systems that allow them to process food. With this project you will design hardware that could be used to monitor these sharks in the wild, including an underwater robot platform, or a mechanism to release and image artificial plankton.",1,UoB,,,,,
Sabine Hauert,sabine.hauert@bristol.ac.uk,"Swarm robotics, swarms for intralogistics, artificial evolution of swarm behaviours, explainable swarms, safe swarms, trustworthy swarms, swarming nano-micro systems for biomedical applications, environmental swarms.","MSc BioRobotics, MSc Robotics",Swarm Post-its for Brainstorming ,"This project explores how a swarm of 100 screen-robots can be used as smart post-its in brainstorming sessions. Each robot can record the thoughts of a participant, and organise with other robots to highlight trends.",1,UoB,,,,,
Sabine Hauert,sabine.hauert@bristol.ac.uk,"Swarm robotics, swarms for intralogistics, artificial evolution of swarm behaviours, explainable swarms, safe swarms, trustworthy swarms, swarming nano-micro systems for biomedical applications, environmental swarms.","MSc BioRobotics, MSc Robotics",Visual navigation and object tracking for industrial swarm robots performing stacking task in a warehouse,"Designing a vision system for multiagent, industrial swarm robots with robotic arm, that can move around and perform objects manipulation and stacking task in a warehouse. The vision system shall be based on dynamic SLAM for localization, mapping, and dynamic object tracking. The robots can use onboard camaras or pixel process array-based SCAMP-5 vision sensor for visual odometry and object tracking. Each swarm robot agent can have dextrous manipulation capability using a tactile end-effector called Tactip . The vision system can be used for locating/tracking the objects that needs to be manipulated, tracking other moving agents and for navigating robot's path around the warehouse.  Each robot can work together with other robots in the swarm to manipulate objects and move around in the warehouse along with human stuff. The experiments shall be performed in simulation and on industrial swarm robots, X-pucks, testbed.",1,UoB,,,,,
Paul O'Dowd,paul.odowd@bristol.ac.uk,"swarm robotics, evolutionary robotics, evolutionary algorithms, mobile robotics, educational robotics, artificial intelligence, artificial creativity, embedded systems","MSc BioRobotics, MSc Robotics",Swarm Spatial Density Estimation,"Swarms of robots are often designed to operate for a specific task and task environment.  In the natural world we can observe a high degree of adaptability of swarm agents across varied environments.  For example, we can observe egg-sorting behaviours of ants within the close-confines of a nest, and foraging behaviours of ants in large spaces outside of the nest.  These two tasks have very different environments.  Inside the nest, ants operate alongside each other with a high spatial density.  Outside of the nest, ants forage with a lower spatial density.  However, the ants are able to adapt their behaviour appropriately depending on their environment.   This observation motivates research to find a technological solution for a swarm of robots to estimate how many robots exist within a task environment.  Such information could be useful for a swarm to adapt or regulate itâ€™s behaviour across different task environments.  For example, it may be useful for some robots to stop their operation when there are too many robots within a space.  Conversely, a swarm of robots may need to maintain a specific degree of spatial-density when they are in unbounded environments, such as outdoors.  Because this is a swarm, the algorithm must remain decentralised and self-organising.  This study will utilise a swarm of Pololu 3Pi+ robots fitted with Infra-red (IR) communication boards.  The project should look to implement a form of complementary filter to combine proprioceptive and exteroceptive information available to the robot, which can then be propagated across the swarm.  For example, messaging frequency between robots may be a useful indication of swarm density, as well as collisions experienced by individual robots.  This study will look to evaluate how well a collective-belief on spatial-density can be established and communicated across a swarm.  If time permits, demonstration behaviours of maintaining specific spatial-densities of robots will be evaluated. ",1,UoB,"[""MSc Robotics"",""MSc Aerial Robotics""]",,UoB,,
Nathan Lepora,n.lepora@bristol.ac.uk,"Robot learning, dexterous manipulation, tactile sensing, deep learning, reinforcement learning, haptics","MSc BioRobotics, MSc Robotics",Virtual telehaptic avatar,"The BRL Tactile Robotics group has a collaboration with Bristol-based company Ultraleap, based on virtual haptic displays where you can feel tactile sensations in mid-air using ultrasonic stimulation (also known as haptic holograms). In this project, we will develop a completely novel application of their technology: virtual telehaptics. We will use the mid-air haptic display to relay sensation from our biomimetic tactile sensor to a human operator, who in turn will control the motion of the sensor (mounted on a robot arm) from the leap-motion sensor built into the haptic display (which tracks hand pose). The aim is for a human operator to control a robot avatar in an immersive way by simply moving their hands above the haptic display. We will explore the capabilities of this technology, with the potential to open up a completely new applications in robot teleoperation.MSc vs CDT project: As this is a co-created MSc project, we are unable to take any more MSc students on this project. We can consider CDT projects, with the potential to develop this technology to controlling complete robot hands. This project is co-supervised by the academic program manager at Ultraleap, Wiliam Frier.",1,UoB,,,,,
Nathan Lepora,n.lepora@bristol.ac.uk,"Robot learning, dexterous manipulation, tactile sensing, deep learning, reinforcement learning, haptics","MSc BioRobotics, MSc Robotics",Human-like dexterity in robots using deep reinforcement learning,"Deep learning methods have revolutionised computer/robot vision and natural language processing, and promise to similarly make a step-change in robot dexterity when applied to tactile sensing. In collaboration with Google DeepMind, the Tactile Robotics group at Bristol Robotics Laboratory has recently introduced a benchmarking task: learning to type on a braille keyboard. So far, this task has been implemented using an industrial robot arm, but the research group has recently developed a low-cost platform that uses an educational robot arm.The aim of this project will be to extend and apply the methods on the educational platform, and find other interesting tasks to demonstrate the capabilities of this system. A very interesting task would be to use touch to control a joystick to learn how to play Atari games using touch, giving an additional level of realism.MSc vs CDT project: For an MSc project we will confine the research to the robot arm.For a CDT project, this work could be extended to control robot hands. In both cases, I advise familiarity with deep learning methods and confidence with python.Reference: Church et al, â€œDeep Reinforcement Learning for Tactile Robotics: Learning to Type on a Braille Keyboardâ€ù, IEEE Robotics Automation Letters 2020.Video: https://youtu.be/eNylCA2uE_E",1,UoB,,,,,
Nathan Lepora,n.lepora@bristol.ac.uk,"Robot learning, dexterous manipulation, tactile sensing, deep learning, reinforcement learning, haptics","MSc BioRobotics, MSc Robotics",Swarm manipulation in industry,"The BRL Swarm Robotics group engineers swarms, with one focus being a swarm of computationally-powerful robots that team up for applications in warehousing. Swarm intelligence allows agents to work together through communicating with their neighbours or via their environment to perform complex tasks.The BRL Tactile Robotics group has a focus on using tactile sensing for intelligent manipulation, and has been using a lightweight robotic arm with tactile end-effector to manipulate objects in its nearby environment.In this project, we aim to combine work from the two research groups to create a novel swarm with dexterous manipulation capabilities. Each robot in the swarm will have a robot arm, which then team together to form a swarm of tactile grippers that can manipulate and flexibly move items around the warehouse. This is a completely novel application of swarms that emerges from leading developments in the two research groups at Bristol Robotics Laboratory.Videos:https://www.toshiba.eu/common/css/ltr/ToshibaNEP/video/Toshiba_Swarm_Robotics_case_study.mp4https://www.youtube.com/watch?v=6fAlHWfLP7I",1,UoB,,,,,
Nathan Lepora,n.lepora@bristol.ac.uk,"Robot learning, dexterous manipulation, tactile sensing, deep learning, reinforcement learning, haptics","MSc BioRobotics, MSc Robotics",Next-generation biomimetic optical tactile sensing,Co-created project with Xuyang Zhang (MSc student),1,UoB,,,,,
Conor Houghton,x,"neurolinguistics, language games, neuroscience, decision making ",MSc BioRobotics,,,,UoB,,,,,
Benjamin Ward-Cherrier,b.ward-cherrier@bristol.ac.uk,"Tactile robotics, neuromorphic processing, spiking neural networks","MSc BioRobotics, MSc Robotics",Neuromorphic tactile perception,"Spiking Neural Networks (SNN) are considered the new generation of neural networks that closely emulate the spike-based information processing undertaken by our own nervous system. This project will aim to investigate the similarities which may be drawn between artificial and human sensing, building upon previous work on the optical neuromorphic tactile sensor (NeuroTac) developed at Bristol. The project will involved the adaptation of the NeuroTac to investigate its potential as a neuromorphic sensor integrated with spiking neural networks. This work may result in a greater understanding of tactile sensing and information processing in biologically plausible models.",1,UoB,,,,,
Benjamin Ward-Cherrier,b.ward-cherrier@bristol.ac.uk,"Tactile robotics, neuromorphic processing, spiking neural networks","MSc BioRobotics, MSc Robotics",Tactile feedback for prosthetic hands,"This project involves exploring tactile sensation in prosthetics, with the aim being to provide high-quality haptic information to amputees. Our system will use OpenBionic'sâ„¢ Brunel hand and provide vibrotactile feedback through a haptic armband. Work on this project will involve investigating feedback quality and comfort with able-bodied participants. The project could inform our understanding of tactile sensation and help develop a real-world solution to deliver feedback to amputees.",1,UoB,,,,,
Hemma Philamore,hemma.philamore@bristol.ac.uk,"soft robotics, bio-hybrid robots, microbial fuel cells, social robots","MSc BioRobotics, MSc Robotics","Gut feeling: Exploring the use of microbes for personality generation in robots. A microbial fuel cell (MFC) can be described as a biological battery that supplies an electrical charge due to electrons released through respiration, as anaerobic bacteria b","A microbial fuel cell (MFC) can be described as a biological battery that supplies an electrical charge due to electrons released through respiration, as anaerobic bacteria break down organic matter inside of the MFC. The electrical output of the MFC is relative to the energy content of the organic matter and the health of the biofilm of bacteria, and therefore provides a) the capability to sense the composition of the organic matter and b) a random individual response of each MFC due to the self-organization of the bacterial colony. The â€œgut feelingâ€ù project has so far looked at using this coupled random and deterministic output to build a personality generator for a robot through simulation. This approach to Artificial Life is a means to introducing the seemingly random variation observed in nature to artificially created agents.  The student will build on this existing work by developing a proof-of-concept MFC â€œartificial gutâ€ù of fluidically connected MFCs and a computer program to read the MFC electrical output and translate this into behaviours such as memory, exploration, and personality. ",1,UoB,"[""MSc Bio-Robotics"",""MSc Robotics""]","Martin Garrad, Jiseon You",UoB,,
Hemma Philamore,hemma.philamore@bristol.ac.uk,"swimming robots, navigation, bio-inpsired robots","MSc BioRobotics, MSc Robotics",Bio-inspired underwater navigation in challenging environments,"Navigation is a key requirement for any autonomous mobile robot. Navigating the underwater environment can pose several challenges. Occlusion, visual disturbance and low light in deep water can make vision-based systems difficult to use. Time-of-flight sensing can suffer from false depth readings caused by light scattering and reflection. Possible solutions, inspired by the natural world include pressure sensing that mimics the behaviour of lateral line sensing which allows fish to detect of pressure differentials in the surrounding fluid. Sensor fusion may also be used to optimise the mutual information gain from multiple sensory signals. This project will investigate novel bio-inspired approaches to improving underwater navigation of confined environments by autonomous robots.  ",1,UoB,"[""MSc Bio-Robotics"",""MSc Robotics""]","Elliot Scott, Hendrik Eichhorn",UoB,,
Hemma Philamore,hemma.philamore@bristol.ac.uk,"soft robotics, devices for communication, human-robot-interaction","MSc BioRobotics, MSc Robotics",Softly-non-spoken ,"Softly non-spoken is a project about using soft robotics to develop non-verbal communication aids (also known as augmentative and alternative communication (AAC)). AAC refer to a set of tools or strategies that range from simple paper-based systems to electronic or digital technologies that enable people to communicate their needs and engage in conversation.  Approximately 300,000 people in the UK have complex communication difficulties that can benefit from external devices or AAC.  People can experience difficulties in communication as a result of a range of conditions; some acquired in birth or early childhood, such as cerebral palsy, others as a result of a medical event or acquired condition that occurs in adulthood, such as a stroke, brain injury or motor neuron disease. Current AAC devices tend to support the delivery of specific content or information from the person using the device, rather than facilitating richer social interaction and dialogue, or allowing for unscripted, spontaneous communication. This project will explore the potential of soft robotics to deliver superior AAC by investigating ways to better understand communication through movement, gesture, or touch, which may also enable more autonomous, unscripted ways of interacting. The project will run alongside an ongoing EPSRC-funded project and there is potential scope to work with industry partners on the project which include speech and language therapists and Air Giants https://www.airgiants.co.uk/.  ",1,UoB,"[""MSc Bio-Robotics"",""MSc Robotics""]",Alice Haynes ,UoB,,
Walterio Mayol-Cuevas,Walterio.Mayol-Cuevas@bristol.ac.uk,"Deep Learning for Robotocs, Computer Vision, Human-Robot Interaction, Novel Robot Concepts, Visual Mapping /SLAM","MSc Aerial Robotics, MSc BioRobotics, MSc Robotics",Visual navigation with a Pixel Processor Array,"This project deals with the development of new computer vision methods suitable for pixel processor arrays (PPAs). These devices combine sensing and processing and have massive parallel computation ability by having a processor for every pixel. These devices offer the ability of very fast processing speeds with reduced energy consumption. But their operation is substantively different to that in conventional visual pipelines. This means that algorithms that usually work well for traditional computer vision do not work well on PPAs. In particular the massively parallel nature of the array benefits from highly parallel computational methods.In this project the objective is to 1) identify and implement visual algorithms for visual navigation that are suitable for PPAs and 2) evaluate them on a robot visual navigation setting.The project will start with a literature review on existing visual navigation methods such as those that use small images or few bits for representation, and then identify suitable ones for implementation and or modification for PPAs. The aim is to then evaluate these algorithms on a navigation task by either localising the camera based on the images it observes and or actually controlling a vehicle based on these images.",1,UoB,,,,,
Walterio Mayol-Cuevas,Walterio.Mayol-Cuevas@bristol.ac.uk,"Deep Learning for Robotocs, Computer Vision, Human-Robot Interaction, Novel Robot Concepts, Visual Mapping /SLAM","MSc Aerial Robotics, MSc BioRobotics, MSc Robotics",Visual perception for handheld robots,In this project the objective is to develop and evaluate methods that are useful for the visual perception of objects that a handheld robot needs to interact with. The principal objective is to develop the computer vision models for the recognition of objects of a few classes from the perspective of a handheld robot. The information would then if time permits be used to control the robot for simulated action. One potential scenario to be considered is the recognition of objects to be recycled into categories. The objects will be simulated on a TV screen for simplicity and within a motion tracking system the handheld robot positioning will be determined. The result of this work will develop understanding about what models for visual perception can work when in cooperation with a human in the loop.,1,UoB,,,,,
Walterio Mayol-Cuevas,Walterio.Mayol-Cuevas@bristol.ac.uk,"Deep Learning for Robotocs, Computer Vision, Human-Robot Interaction, Novel Robot Concepts, Visual Mapping /SLAM","MSc Aerial Robotics, MSc BioRobotics, MSc Robotics",Computer Vision with Deep Learning for Wearable or Robotic systems,"We can work on ideas with you for cameras that move carried by people such as a go-pro or google glass type cameras or on robots virtual or real.In my team  we have developed Computer Vision with Deep Learning that is for  understanding what people is doing or how well they are doing things that can  be used to teach robots or intelligent assistants.https://www.youtube.com/watch?v=GO5pBQA5PhI&feature=emb_logoOr recognize objects or hands. We can work on this topic to find alignment.",1,UoB,,,,,
Walterio Mayol-Cuevas,Walterio.Mayol-Cuevas@bristol.ac.uk,"Deep Learning for Robotocs, Computer Vision, Human-Robot Interaction, Novel Robot Concepts, Visual Mapping /SLAM","MSc Aerial Robotics, MSc BioRobotics, MSc Robotics",Visual-based semantic SLAM for navigation in dynamic environment,"Although the current traditional visual SLAM technology performs well in mapping and 3D construction in static environment, it may not be enough to relocate it based on feature points, thus extracting semantic information from the scene may help it relocate.RGB-D cameras are suitable for indoor use, so if we want to use this camera, we need to simulate the indoor scene and add dynamic objects or people. Semantic slam can use object detection, semantic segmentation, or instance segmentation to detect landmarks. In addition, some algorithms are used, such as the optical flow-based method to remove the feature points in segmented landmark, because the calculation of the geometric relationship of the pose is based on the rigid body environment. After the 3D-Map is built, the feature points and semantic information can be used for navigation. Adding some other methods of localization can also be considered.RGB-D camera is bad to use in outdoor environment due to unstable illumination and weather, so binocular camera can be used to realize semantic SLAM in KITTI dataset.",1,UoB,,,,,
Walterio Mayol-Cuevas,Walterio.Mayol-Cuevas@bristol.ac.uk,"Deep Learning for Robotocs, Computer Vision, Human-Robot Interaction, Novel Robot Concepts, Visual Mapping /SLAM","MSc Aerial Robotics, MSc BioRobotics, MSc Robotics",Visual localisation in the wild,"Robust localisation is a necessary sub-problem for robots to operate in the real world. This project is inspired by the fact that animals can effectively navigate dynamicenvironments with sparse feedback and in some cases low-resolution sensor data. The objective of this project is to explore what constitutes good visual feature representations for place recognition in diverse environments. Some preliminaryhypotheses are:-  How small is too small? The optimal input image size for recognition. - The role of attention and saliency maps. - Are semantics relevant for efficient representations?- Can a vision system recursively explore good representations based on the model of uncertainty of its predictions? - Is place recognition with directions enough for navigation? ",1,UoB,,,,,
Wenhao Zhang,wenhao.zhang@uwe.ac.uk,computer vision; deep learning; face recognition,MSc Robotics,Occluded face recognition,"While generic face recognition techniques are gaining increased accuracy and reliability, challenges brought by a large area of occlusion is still having a significant impact. For example, numerous face recognition systems would fail to detect or recognise a face when a person is wearing a face mask. This project therefore investigates a deep neural network to recognise occluded faces. Appropriate data augmentation methods will be used to simulate severe face occlusiosn.",1,UWE,"[""MSc Robotics""]",,UWE,Jialin Lin,Yes
Wenhao Zhang,wenhao.zhang@uwe.ac.uk,computer vision; deep learning; biometrics,MSc Robotics,Biometric recognition from eye movements,"Eye movement patterns can be novel types of biometric data that are unique to an individual and are more spoof-proof than conventional types of biometrics such as faces and fingerprints. In this project, different machine learning models will be designed and compared to explore spatial-temporal features that can encode the uniqueness of eye movement patterns of individuals. Publicly availalble datasets will be employed to validate experiment results. ",1,UWE,"[""MSc Robotics""]",,UWE,Tengfeng Zhang,Yes
Wenhao Zhang,wenhao.zhang@uwe.ac.uk,computer vision; machine learning; eye tracking,MSc Robotics,Eye tracking in reality and virtual reality,"Conventional psychological and medical studies using an eye tracking device takes place in a real world environment, where a person's eye movements can be limited by physical constraints such as the size of the screen. When a virtual reality environment is created around a user, the immersive experience and flexible setting has the potential to induce different user behaviours which may provide significant cues that do not exist in a real-world environment. In this project, a VR headset is employed and compared to a webcam based eye tracker in exploration of the additional advantages that a VR eye tracker can offer.",1,UWE,"[""MSc Robotics""]",,UWE,Hari Rengasamy Balakrishnan,Yes
Wenhao Zhang,wenhao.zhang@uwe.ac.uk,"machine learning; object detection, 3D vision",MSc Robotics,Depth estimation from a single camera,The ability to estimate the depth of an object using a single camera can be a cost-efficient alternative to different types of 3D cameras. This project investigates a method using an object whose size is automatically detected by a deep learning model to calibrate estimated depth. Comparison to alternative approaches and existing 3D cameras will be carried out.,1,UWE,"[""MSc Robotics""]",,UWE,Han Zhang,Yes
Roshan Weerasekera,roshan.weerasekera@uwe.ac.uk,Neuromorphic Hardware Systems ,MSc Robotics,Osillatory Neural Networks for Robotic Manipulations,,1,UWE,,,UWE,,
Yaseen Zaidi,yaseen.zaidi@uwe.ac.uk,"Model Based Systems Engineering, continuous-time, numerical simulations, co-simulation, stiff, SysML",MSc Robotics,Modelling of Stiff Behaviours in Spacecraft Systems with Model Based Systems Engineering (MBSE) Framework,"The space engineering community prefers the model-based systems engineering (MBSE) methodology for systems modelling. The MBSE largely uses discrete-event models for abstracting behaviours. More than often, the desired physical behaviours in the space applications are stiff requiring highly non-linear dynamics that are difficult to model in discrete-event simulators. This work aims to co-model/co-simulate continuous-time behaviours in an MBSE framework (hybrid discrete-event and continuous-time). Problems such as Robertson's kinetics of different time-constants, bouncing ball root detection, Van der Pol non-steady-state and Jiles-Atherton hysteresis loops will be taken to be simulated with a differential-algebraic solver integrated into SysML activity diagrams developed in an MBSE tool (Modelio, MagicDraw, Cameo, Capella, Enterprise Architect). Optionally, orbit propagators in AGI Systems Tool Kit may be integrated. http://sysml-models.com/spacecraft/models.html The expectation is to share the results with the INCOSE UK MBSE Interest Group and publish them in the IEEE Systems Journal or Wiley Journal of Systems Engineering.",1,UWE,"[""MSc Aerial Robotics""]",,UWE,,
Yaseen Zaidi,yaseen.zaidi@uwe.ac.uk,"Mission design, rover, telemetry, programming, visualisation",MSc Robotics,"Rover Mission Design, Analysis and Telemetry Visualisation with OpenMCT","The student should understand the current research and open problems in the OpenMCT rover mission simulator and confirm with the supervisor software development of interesting mission scenarios for improving telemetry collection, terrain navigation, imagery, etc. such as (Perseverance rover capturing Mars Ingenuity rotorcraft flight. ",1,UWE,"[""MSc Aerial Robotics""]",,UWE,,
Yaseen Zaidi,yaseen.zaidi@uwe.ac.uk,"Steerable, CubeSat, thrusters, degrees of freedom, thrust vector, mechanism",MSc Robotics,Steerable Thrusters on a CubeSat ,"Agility in maintaining the orbit or CubeSat spacecraft attitude may be accomplished by avoiding fixed thrusters. A mechanism steerable in 2 or more degrees of freedom would orient the thruster and control the direction of thrust. Possible technologies are gimbals, linear actuators of a Stewart platform, or one-way or two-way shape memory alloys. The task is to develop one of these mechanisms to change the thruster vector of a minimum 3U CubeSat inertia (~4 kg).",1,UWE,"[""MSc Aerial Robotics"",""MSc Robotics""]",,UWE,,
Yaseen Zaidi,yaseen.zaidi@uwe.ac.uk,"Digital twin, digital factory, VR, product lifecycle management",MSc Robotics,Digital Factory Twinning in VR Environment,"Industrial partner: CIMPA PLM. The project aims to solve several problems raised in detection and imaging with a VR handset in the digital factory. Digital factory twin is a reference solution that simulates the manufacturing environment that creates the product and implements bi-directional data exchange between real and simulated environments. The solution addresses end-to-end integration by gathering data coming from IoT layers (sensors, systems, smart tools, smart objects) and connecting it to the Product Lifecycle Management (PLM) process with configuration management and Product Data Management (PDM) software. The student should be willing to travel to the partner premises in Filton.",1,UWE,"[""MSc Robotics""]",Chris Toomer,UWE,,
Mark Hansen,mark.hansen@uwe.ac.uk,"Machine vision, machine learning, agritech, reinforcement learning",MSc Robotics,GANs for synthetic art production,"There has been a lot of interest in recent years in bridging the gap between artists and computer scientists in the area of art generation. The project itself is very open ended, and could look, for example, at genertaing specific types of objects for inclusion in larger images, or how to combine them in an aesthetically pleasing way, or even creating a robot that can interpret instructions and generate something new.",1,UWE,,,,,
Mark Hansen,mark.hansen@uwe.ac.uk,"Machine vision, machine learning, agritech, reinforcement learning",MSc Robotics,Machine Vision in Agriculture,Many ideas for projects in this domain such as: Developing a means of performing in-field phenotyping; Automated cow or pig recognition; In field potato measurement using a portable rig via 3D reconstruction/photogrammetry,1,UWE,,,,,
Mark Hansen,mark.hansen@uwe.ac.uk,"Machine vision, machine learning, agritech, reinforcement learning",MSc Robotics,CNNs learning to ignore,CNNs are excellent classifiers but there are cases when they might learn to classify objects correctly based on incorrect information for example when the training set is contains cues that the validation set does not. Is there a way to force the network to find other features that are reliable instead of these cues?,1,UWE,,,,,
Mark Hansen,mark.hansen@uwe.ac.uk,"Machine vision, machine learning, agritech, reinforcement learning",MSc Robotics,Insect sexing and counting ,"Insect farming is likely to become more common in the future as a source of livestock feed. Finding ways of optimising conditions for the insects in order to automate the process are likely to be extremely useful. Sexing and counting the insects (such as crickets) are two such areas that are important parameters to measure and seem to lend themselves to machine vision, but there are many others.",1,UWE,,,,,
Manuel Giuliani,manuel.giuliani@uwe.ac.uk,human-robot interaction,MSc Robotics,BRL Reception Support Robot: Long-term operation and visitor interaction,"BRL Reception Support Robot: Long-term operation and visitor interaction  The aim of this dissertation project is to investigate a robot that is supporting the reception at the Bristol Robotics Laboratory (BRL). The tasks and specification of the robot are as following: â€¢	Interacting with the BRL receptionist, visitors, lab staff and students, e.g. by displaying short spoken messages.  â€¢	Leading visitors to spaces in BRL. â€¢	Assisting visitors with the registration process at BRL. â€¢	The robot will have a touch screen that acts as input modality for humans to give commands to the robot. â€¢	The main output of the robot will be spoken language through a text-to-speech system. â€¢	The robot needs to be able to run long-term, ideally it should be running during office hours.  â€¢	The robot needs to monitor its own state and e.g. be able to return to its charging station (or alternatively alert a human to attach it to a charging station). â€¢	Optionally, the robot should also be able to produce usage statistics (e.g. how long it is running each day, how many interactions and type of interactions it had during the day).  The skills needed to be able to complete this project are as follows: â€¢	Knowledge in ROS and Python to program the robot. â€¢	Knowledge in simultaneous localization and mapping (SLAM) and path planning. â€¢	Knowledge in software engineering tools, e.g. Git for code versioning, tools to create code base documentation.",1,UWE,"[""MSc Robotics""]",,,,
Matthew Studley,Matthew2.Studley@uwe.ac.uk,Industrial Case Study on Ethics and Impacts of Robotics and Automation,MSc Robotics,Swarm dynamic task allocation,"A set of tasks, such as pruning plants in a horticulture application, needs to be accomplished by a swarm of robots that have minimal communications and no central controller.  This project will investigate the mechanisms and communications requirements for a swarm of simulated robots to dynamically self-allocate to optimise time and motion efficiency, using a variety of biologically inspired approaches.",1,UWE,,,,,
Matthew Studley,Matthew2.Studley@uwe.ac.uk,Industrial Case Study on Ethics and Impacts of Robotics and Automation,MSc Robotics,Remote Robotics Outreach,"Robots will have an enormous impact on all our lives, and it is vital that all sectors of our society can shape, and benefit from, this new technology.Kids love robots.  In this project you will develop and run an outreach activity in which we monitor the success of the project remotely using the robots which we will deliver to the school, etc.The purpose of the project will be to assess the impact of role models on children's perceptions of robotics and STEM as a career; can we widen the discipline to include more female and BAME voices?For further information about this project, which will take place alongside the [DETI] (https://www.digicatapult.org.uk/for-large-businesses/commercial-solutions/deti-digital-engineering-technology-and-innovation), see [here](https://docs.google.com/document/d/1ZhuZOWMsVihOVGmGG4kXKaoLaiIF3hgCQzFabvCCG34/edit?usp=sharing)https://docs.google.com/document/d/1ZhuZOWMsVihOVGmGG4kXKaoLaiIF3hgCQzFabvCCG34/edit?usp=sharing",1,UWE,,,,,
Tavs Jorgensen,tavs.jorgensen@uwe.ac.uk,"Ceramic extrusion, Robotic Arm, CNC bending, Collaborative Robot, Cobots",MSc Robotics,Robotic Assisted Bending of Ceramic Extrusions  ,"This project will contribute to development of a novel robotic system to shape extruded sections as the clay - with the aim of creating curved forms that correspond to dimensions of CAD designs. We are looking to use Universal Robots Arms for the project, but also open to the possibility of using other types of computer-controlled actuators. The research is located at UWE's Centre for Fine Print Research (CFPR) and is part of an externally funded project.  The main challenge is likely to be the development of bespoke code and scripts that can translate CAD drawings into machine control data and facilitate the production of physical pieces in corresponding forms. The project may also involve the development of the physical actuators, electronics, mechanics and CAD. The development of the system is likely to involve notions of Control Theory and Compliance. The coding environment is not pre-determent, but likely involve UR script, Python and Rhino Grasshopper.",1,UWE,,,,,
Tavs Jorgensen,tavs.jorgensen@uwe.ac.uk,"Ceramic extrusion, Robotic Arm, CNC bending, Collaborative Robot, Cobots",MSc Robotics,Development of Robotic 3D printing for Architectural Ceramics,This project is focused on the further development of 3D printing with ceramic paste for large scale ceramic parts for architectural applications. The project will look to create bespoke code and scripting for the control of complete 3D printing systems â€“ also potentially involvement in the creation of bespoke hardware and practical tests with the system.,1,UWE,,,,,
Farid Dailami,Farid.Dailami@uwe.ac.uk,Industrial Robotics and Automation,MSc Robotics,An Industry 4.0 demonstrator for product storage systems,,1,UWE,,,,,
Farid Dailami,Farid.Dailami@uwe.ac.uk,Industrial Robotics and Automation,MSc Robotics,Hand over from robot to humans in an industrial context,,1,UWE,,,,,
Farid Dailami,Farid.Dailami@uwe.ac.uk,Industrial Robotics and Automation,MSc Robotics,Vision assisted Collaborative manufacture of jewelry,"The project intends to create an Industrial collaborative solution for Manufacturing of jewelry. The aim of the project is to deploy a collaborative robot with vision system- ABB YUMI for manufacturing of jewelry and to assist the associate by performing tasks like grinding, polishing and quality check alongside the associate. the project aims to target rings as the form of jewelry for manufacturing purposes.",1,UWE,,,,,
Farid Dailami,Farid.Dailami@uwe.ac.uk,Industrial Robotics and Automation,MSc Robotics,Path generation for repairing a damaged part,"Main aim:The project has a goal to generate a welding path for repairing a damaged aerospace part. The part is firstly scanned using a vision system. The system needs to locate the damaged part and generate a welding path to make the part back to its original shape.Background:The aerospace part works in a very harsh environment especially because of a very strong air stream. This part is very expensive to build from scratch and cheaper to repair the damaged one. The existing repairing process is still done by manual welding workers which is can be optimized by using robotic technology. There are three main types of how to program a robot. The first and second ones are off-line programming mode and teaching-playback mode. These types of programming are not effective to be applied in the part repairing process because the parts may have different damaged shape and location. Thus, welding path generation using a vision system needs to be designed for this process.",1,UWE,,,,,
Farid Dailami,Farid.Dailami@uwe.ac.uk,Industrial Robotics and Automation,MSc Robotics,Support removal in metallic additive layer manufacturing,,1,UWE,,,,,
Farid Dailami,Farid.Dailami@uwe.ac.uk,Industrial Robotics and Automation,MSc Robotics,Autonomous painting robot in construction industry,,1,UWE,,,,,
Farid Dailami,Farid.Dailami@uwe.ac.uk,Industrial Robotics and Automation,MSc Robotics,Robotic cutting of large oil platform structures,,1,UWE,,,,,
Farid Dailami,Farid.Dailami@uwe.ac.uk,Industrial Robotics and Automation,MSc Robotics,Classification of waste using machine learning,"This project aims to automate the final sorting stage of waste recycling, in order to provide a cheaper, more efficient alternative to a task which is commonly completely by a team of human labourers. This project will first require accurate real time classification of the different waste materials present on the picking line, with challenges such as occlusion of different objects having to be overcome. In order to achieve this a variety of different sensors will mostly likely have to be used, this will form my initial research and literature review, with novel sensor solutions also being considered. Once classified, a robotic system will be designed and implemented in order to move the classified objects, of various weights, shapes and sizes to their respective goal points, different manipulators will have to be considered and performance of different end effector tools on different types of objects analysed.",1,UWE,,,,,
Farid Dailami,Farid.Dailami@uwe.ac.uk,Industrial Robotics and Automation,MSc Robotics,Motor operation prototype,"DiGiPulse Ltd is a start-up company aiming to position itself as a specialist technology leader in the market for high-efficiency motor software and hardware.  It will offer clients software and hardware that improves motor efficiency, especially in part-load operation, commensurate with new system-level control systems being adopted into domestic and mid-sized commercial plants (refrigeration, HVAC, and process industries).This project will deliver a first physical prototype to demonstrate improved part-load operation of a motor, using DiGiPulseâ€™s control software â€“ and will provide a back-to-back comparison of a commercially available PWM-controlled motor, with and without DiGiPulseâ€™s control software, in at least one operating condition.The project is seeking a researcher capable of implementing DiGiPulse control logic onto a hardware platform (Digital Signal Processor or simple PC, e.g. Raspberry Pi) and interrupting the control signals of a commercially available PWM-controlled motor at the point of GDA input (Gate Driver Array). This researcher will also need to turn and calibrate the self-built motor controller (for at least one operating point), so that the controllerâ€™s performance can be assessed on a like-for-like basis with the fully tuned and calibrated commercial motor that constitutes the baseline for this study.",1,UWE,,,,,
Martin Pearson,martin.pearson@brl.ac.uk,"Neurorobotics, Deep Predictive coding, SLAM",MSc Robotics,Sparse training of a Deep Predictive Coding network,"Deep learning has revolutionized data science and is transforming many aspects of robotics particularly perception. However, it has fundamental algorithmic differences to known brain function and can not serve as a complete model of biological significance. Neurorobotics is an area of robotics research that is motivated toward understanding the brain through the evaluation of situated, robotic embodiment of brain models. For this we have been investigating the next generation of deep machine learning algorithms, namely, Deep Predictive coding Networks (DPN) that have a closer affinity to biologically plausible algorithmic models of the cortical microcircuit. DPN are similar to Variational AutoEncoders in that they learn a generative model without extensive labelled training sets, instead using the patterns and structure of the sensory input itself. In this project you will be evaluating the performance of a DPN at learning a simple 1D state estimation problem (head direction) from visual scenes taken from a mobile robot. The primary research question will be to find the minimum size of training set that is required to maintain a baseline performance. This could involve filtering the visual scene for salient features (landmarks), influencing the behavior of the robot during learning, or perhaps a revision of the network learning rules themselves. The secondary research question will be to evaluate how new environments can be accommodated into this model without incurring catastrophic forgetting of previously learnt environments.This will be a software based project using the Tensor Flow library for Deep learning and a ROS controlled Gazebo simulation of a biomimetic robot ""WhiskEye"" to gather data sets for training and validation. Existing code for DPN will be provided along side starter data sets for familiarization and initial experimentation. You will be expected to collect your own data sets from the simulator and to modify the controller for the robot as necessary. Proficiency in the Python programming language is essential and familiarity with ROS would be beneficial.",1,UWE,"[""MSc Robotics""]",,,,
Martin Pearson,martin.pearson@brl.ac.uk,"Neurorobotics, SNN, SLAM",MSc Robotics,Encoding robot motion using spike based hardware,"Neuromorphic hardware has the potential to revolutionize AI and robotics in the future through its greatly reduced energy requirement and brain inspired, massively parallel compute architecture. To best leverage this hardware we look to neuroscience for inspiration, here we have learnt that information is represented through myriad spatio-temporal spike based encoding schemes which have yet to be fully understood. One of the research projects in the BRL is developing a spike based model of the rodent spatial navigation system to test hypotheses from biology in an embodied, situated biomimetic robotic model of the rat. One of the inputs to this model comes from an analogue measure of the robot's own motion which we convert into a spike rate through a simple transfer function. We have found that this naive ""hack"" is insufficient for stable localization outside of a limited range of velocities when applied to our spiking neural network model. In this project you will address 2 research questions; first, how best to encode robot motion into spikes that can represent and respond to a broad range of velocities; and secondly, how can that encoding be adapted in response to systematic changes in the characteristics of robot motion over time. The second question leads from results taken from animal behaviour experiments that demonstrate how rats modify their representation of self motion in response to environmental changes.This will be a primarily software based project using tools such as NEST, a software spiking neural network simulator, and a ROS controlled Gazebo simulated model of the whiskered biomimetic robot called ""WhiskEye"". You will be working with researchers on the project who will provide test data sets and guidance to understand the prior model. Proficiency in the Python programming language and a keen interest in neuroscience is essential.",1,UWE,"[""MSc Robotics""]",,,Anna Summerton,Yes
Martin Pearson,martin.pearson@brl.ac.uk,"Neurorobotics, SNN, SLAM",MSc Robotics,Olfaction for place recognition,To integrate olfactory cues into a multi-sensory place recognition system based on the principles of predictive coding neural networks. This project will feed into a model of a cortico-hippocampal loops as the basis for spatial cognition in mammalian brains and as the inspiration for next generation spike based robotic control.,1,UWE,"[""MSc Robotics""]",,,,
Ning Wang,Ning2.Wang@uwe.ac.uk,"Connected and Autonomous Vehicle (CAV); Assistive living; intent prediction, intelligent vehicular system, smart driving, data analysis",MSc Robotics,Driver intent prediction for smart driving assistance,"Driving is a complex, dynamic and time-varying process. Different drivers vary in driving habits and operation style. In order to enhance the mutual communication and to encourage cooperation between a driver and the vehicle, we are motivated to build a smart driving assistance system, which owns self-learning capability through sensing, signal processing techniques and intelligent learning methodology. An Intelligent Vehicular System would have to infer the intentions of the driver and help or intervene only when needed. For the development of a novel Smart Assistance System we will need to have a prediction mechanism by combining information from both sources â€“ vehicle and user. Multiple information sources, e.g., steering forces, speed, position of the vehicle, etc., will be combined to analyse the state of the car and the intent of the driver in this study.",1,UWE,,Tony Pipe,UWE,,
Ning Wang,Ning2.Wang@uwe.ac.uk,Connected and Autonomous Vehicle (CAV); Autonomous agent; Machine learning.,MSc Robotics,Generalizable driving skills transfer from driver to smart vehicle,"In achieving the ultimate goal of autonomous driving, at the current stage, it is expected that smart vehicles can assist human driver in part of the driving when needed, namely co-driving. In this project, we will look at the skills that could be transferred from human driver to the smart vehicles, as part of the modern driving assistance strategy. Endowing the vehicle with human-like driving skills can not only improve the autonomous driving performance, but can make the co-driving experience more user-friendly. Motor skills like the motion in steering, and force-related skills like the press of pedals, could be considered as the driving skills to be transferred to the smart vehicles. It is also expected that the learned skills could be generalized in broader scenarios when necessary, which means the smart vehicle can flexibly adopt different yet similar skills according to varying driving environments.",1,UWE,,Tony Pipe,UWE,,
Ning Wang,Ning2.Wang@uwe.ac.uk,Connected and Autonomous Vehicle (CAV); Remote driving; Smart vehicles.,MSc Robotics,Remote assistance for smart vehicles,"Teleoperation has already been used to explore the worldâ€™s oceans and defuse bombs. Amid the COVID-19 crisis, however, teleoperation â€“ whether taking control of a vehicle remotely or offering indirect â€œremote assistanceâ€ù â€“ could take on greater importance, as it minimizes social contact. However, the remote controlled vehicles highly rely on the high-speed cellular connection for long durations, which is never 100% stable. Remote assistance hereby offers an alternative approach, i.e., let the vehicle self-drive autonomously and only intervene when there is a need, e.g., a lane is blocked as a result of a road accident. In this project, we are going to explore the remote assistance method that can detect and identify unknown and unsolvable conditions by self-driving and then issue an alarm to the remotely standby human operator/controller to provide necessary assistance. This involves issues like scenario analysis, object detection and distance estimation, etc.",1,UWE,,Tony Pipe,UWE,,
Ning Wang,Ning2.Wang@uwe.ac.uk,Mobile robots; autonomous navigation; remote control; elderly care ,MSc Robotics,Mobile robot for elderly care in home environments,"Elderly people are often not able to perform all activities of their daily life without the help of caregivers and face a higher risk of experiencing a medical emergency in unattended situations. Therefore, they usually have to move to assisted living facilities where they are looked after by the nursing staff. Due to limited number of nursing staff and increasing costs of such facilities, many research groups use modern technologies to assist elderly people at their homes. The aim is not only to lower the nursing costs but also to increase the quality of life of senior citizens. In this project, an in-door mobile robot will be able to navigate autonomously through narrow corridors and closely placed furniture in the living environment. It can follow the elder people at home, detect emergency such as falling down, and remote controlled by people for simple in-house tasks such as deliver small items. ",1,UWE,,Charlie Yang,UWE,,
Amir Bolouri,Amir.Bolouri@uwe.ac.uk,Smart structures for soft-robots ,MSc Robotics,,,,UWE,,,,,
David Western,david.western@uwe.ac.uk,"Augmented Reality, Clinical Neurophysiology, Computer Vision",MSc Robotics,Markerless 3D Human Motion Capture for Home Environments,"Recently developed computer vision tools such as OpenPose allow detailed human pose information to be automatically extracted from ordinary videos.  This project aims to build on such tools for human health applications. Specific tasks to focus on could include automated extrinsic calibration, fall detection, monitoring of movement disorders, or others.",1,UWE,,,,,
David Western,david.western@uwe.ac.uk,"Augmented Reality, Clinical Neurophysiology, Computer Vision",MSc Robotics,Augmented Reality System to Guide Electrode Placement for Clinical Electrophysiology,"Various important medical diagnostic and therapeutic procedures involve measuring electrical activity generated by the brain, nerves, muscles, or heart. The reliability and quality of results in these procedures depends largely on the accuracy in placing electrodes over anatomical regions of interest. Conventional practice for measuring these target locations by hand is time consuming and error prone.  In this project, the student will develop an Augmented/Virtual Reality system that automatically identifies target locations on the patientâ€™s body and enables the clinician to â€˜seeâ€™ these targets superimposed on the body as they position the electrodes, so that they can be positioned quickly and accurately. ",1,UWE,,,,,
David Western,david.western@uwe.ac.uk,"Augmented Reality, Clinical Neurophysiology, Computer Vision",MSc Robotics,Analysis of Brain Networks to Quantify Consciousness and Cognitive Function,"Graph theory and network analysis represent a fast-growing area of mathematics, with numerous applications including the analysis of brain activity.  In this project, the student will develop software to apply existing and/or novel measures of network structure and activity to real and/or simulated brain networks. The project could lead to much needed improvements in our ability to assess levels of consciousness during general anaesthesia (i.e. during surgery) or to monitor changing cognitive functioning in conditions such as dementia. Improving our ability to measure such traits is crucial in enabling improvements in how we treat them.",1,UWE,,,,,
David Western,david.western@uwe.ac.uk,"Augmented Reality, Clinical Neurophysiology, Computer Vision",MSc Robotics,Deep Learning for Clinical Neurophysiology,"The NHSâ€™s neurophysiology departments provide vital diagnostic and prognostic information that informs the treatment of a wide range of conditions, including neurodegenerative diseases, traumatic brain injuries, stroke, and epilepsy to name only a few. A particular investigative tool, electroencephalography (EEG), is well established as a rich source of neurophysiological information. However, the extent of current use of this tool within the NHS falls well short of guidelines, due to a shortage of trained neurophysiologists to interpret the data. Researchers have begun to attempt to develop AI systems to support neurophysiologists in their work, but there is much progress to be made. In this project, the student will aim to advance the state-of-the-art, working with an open-access EEG dataset.",1,UWE,,,,,
David Western,david.western@uwe.ac.uk,"Augmented Reality, Clinical Neurophysiology, Computer Vision",MSc Robotics,Intelligent Infrared Beamforming: the Future of Home Heating,"The aim of this project is to explore the feasibility of a new concept for domestic home heating: infrared panels that can selectively focus their energy on room occupants and/or cold spots, e.g. where mould is likely to form. This could be achieved in various ways, such as â€˜phased arraysâ€™ for beamforming and readily available computer vision software (e.g. OpenPose) for human motion tracking. With the addition of facial recognition or other ID techniques, it could even be possible to allow different occupants of a single household to experience different temperatures according to their preferences or health requirements.",1,UWE,,,,,
David Western,david.western@uwe.ac.uk,"Augmented Reality, Clinical Neurophysiology, Computer Vision",MSc Robotics,Where Are My Glasses? Machine Vision and Speech Interaction in the Smart Home to Support People with Dementia,"In this project, the student will build upon a previous project that combined object recognition (e.g. YOLO) and speech interaction (e.g. SNIPS) software tools to develop a system to provide useful information about the home for people with memory problems.  For example, I someone asks the smart home â€œWhere did I leave my reading glasses?â€ù the home should be able to reply based on tracking the location of those glasses with cameras around the house (â€œI see them.  Theyâ€™re on your head.â€ù).  More advanced variants of this system could incorporate activity recognition algorithms to provide richer contextual information.  ",1,UWE,,,,,
David Western,david.western@uwe.ac.uk,"Augmented Reality, Clinical Neurophysiology, Computer Vision",MSc Robotics,Development of an Interactive Projector to Provide Ubiquitous Graphical Interfaces for Smart Homes,"Tablets, smartphones, and audio assistants such as Amazonâ€™s Alexa have made it easier than ever to access information quickly from anywhere in the home, but there is room for improvement.  For example, if youâ€™re following a recipe in the kitchen, the audio version can be difficult to navigate intuitively while the on-screen version risks getting flour and oil all over your precious tablet.  An alternative is to project the screen onto the walls / furniture and use a camera to identify hand gestures / pointing as a mode of interaction.  Interactive projectors already exist e.g. for classroom use, but various technical challenges have prevented them from being successfully applied to in-home use.  In this project, the student will aim to overcome some of these challenges and produce a working prototype of some part of this system.  The student may choose challenges in electronic / robotic design, 3D geometry, and/or programming to suit their particular skills and interests.",1,UWE,,,,,
David Western,david.western@uwe.ac.uk,"Augmented Reality, Clinical Neurophysiology, Computer Vision",MSc Robotics,Opto-genetic Tremor Suppression: Simulation and Feasibility Analysis,"Tremor (involuntary rhythmic movement of a body part) is a highly disabling symptom of various neurological diseases.  Various treatments exist, but none is universally successful and all have significant drawbacks.  The newly emerging field of opto-genetics offers a potential solution that has not yet been explored.  In short, a specially engineered virus may be delivered to a cell such that itâ€™s behaviour may be controlled by shining light on the cell.  When applied to motor neurons, this may allow a specific muscle to be temporarily weakened or paralysed to prevent unwanted movement.The objective of this project is to develop a simulation of an opto-genetically controlled muscle (making use of established neural simulators), then use that simulation to explore the potential of this approach from a control theory perspective (e.g. what are the limits of the extent to which movement dynamics may be controlled?). ",1,UWE,,,,,
David Western,david.western@uwe.ac.uk,"Augmented Reality, Clinical Neurophysiology, Computer Vision",MSc Robotics,Using a Smartwatch to Detect and Disrupt Obsessive Compulsive (OCD) Hand Washing,"Obsessive compulsive disorder (OCD) is a highly debilitating mental health condition that can manifest in various ways, but one of the most common forms is compulsive hand-washing. The obsessive/compulsive nature of the patientâ€™s thought processes make it difficult for them to independently disrupt their behaviour. The aim of this project is to develop software to automatically recognise compulsive handwashing using smartwatch sensor data. This could ultimately be implemented in a smartwatch app to trigger alerts or even establish live communication links to a therapist in order to help the patient disrupt their compulsion and practice their therapeutic techniques.",1,UWE,,,,,
David Western,david.western@uwe.ac.uk,"Augmented Reality, Clinical Neurophysiology, Computer Vision",MSc Robotics,COVID-Cam: Using computer vision to track viral contamination in shared spaces,"One way to address infectious diseases/viruses such as COVID-19 is to help people visualise which surfaces or spaces are most likely to be contaminated, so that they can be cleaned and/or avoided. The aim of this project is to enable this approach using computer vision techniques. Existing human motion tracking software (e.g. OpenPose) may be used with conventional or depth-sensing cameras to monitor peopleâ€™s behaviour in a space. Touch-based contamination may be monitored simply by recording and visualising which surfaces have been touched in the last X hours. In more advanced implementations, simple conservative models could be applied to visualise airborne contamination by automatically recognising behaviours such as speech or sneezing. Ultimately, such a system could be used in various ways, such as: 1) to inform efficient deployment of cleaners to de-contaminate priority areas in hospital wards, 2) to inform public behaviour, e.g. choosing a seat in a GP waiting room based on a live heatmap showing contamination risk spots in the room, 3) informing the general public or specific institutions with visualisations showing how a virus can be transmitted around any given space, to encourage and support more hygienic behaviour.",1,UWE,,,,,
Chenguang Yang,Charlie.Yang@uwe.ac.uk,Robot assisted manufacturing,MSc Robotics,Robot-assisted Composite Sheet Layup Skill Learning and generalization through Perception Feedback,"Composites are increasingly becoming a material of choice in the aerospace and automotive industries. Currently, many composite parts are produced by manually laying up sheets on complex molds. Composite sheet layup requires executing three main tasks: (1) grasping a sheet and (2) draping it on the mold (3) layup the sheet. Automating the layup process requires automation of these three tasks. Human-robot skill transfer has been proved an effective method to achieve the automation of the layup process. However, it is still difficult to generalize to novel situations, such as variance in the object shape. Online perception information, such as visual feedback, is vital to reactive online modification to tackle these challenges. Therefore, this project will focus on robotic grasping, online perception processing, and integrating with the layup skill model to improve reactivity and safety and generalization. In this project, deep learning and machine learning techniques etc., will be used. So, the student is expected to have basic knowledge of Python, computer vision and machine learning etc.",1,UWE,,,UWE,,
Chenguang Yang,Charlie.Yang@uwe.ac.uk,Mobile robot teleoperation and robot learning,MSc Robotics,Robot-assisted ultrasound scanning skill learning to optimize ultrasound image quality,"Ultrasound (US) imaging is commonly employed for the diagnosis and staging of abdominal aortic aneurysms (AAA), mainly due to its non-invasiveness and high availability. Robot-assisted tele-echography is an effective method to achieve medical examination. This project will mainly study how to optimize ultrasound image quality by using adaptive compliant control, computer vision and robot skill learning techniques. Robot learning techniques, such as imitation learning and reinforcement learning, will be used in this project. We could provide experimental phantom and Franka Panda platform for experiment. So, the student is expected to have basic knowledge of Python, computer vision and machine learning. ",1,UWE,,Ning Wang,UWE,,
Chenguang Yang,Charlie.Yang@uwe.ac.uk,Mobile robot teleoperation and robot learning,MSc Robotics,Development of a multi-functional mobile robot manipulator,"Mobile manipulator is usually built with a robotic manipulator arm mounted on a mobile platform. This project will investigate combination of various manipulators and different type of mobile platforms, e.g., wheeled or tracked, differential drived or omni-directional. The mobile manipulator can be fully autonomous or teleoperated and is supposed to be able to access space not easy to be accessed by human users. The develop mobile manipulator can be multi-functional with application to various sencarios, such as disposal of dangerous objects, remote inspection and mobile charging station. ",1,UWE,,Ning Wang,UWE,,
Chenguang Yang,Charlie.Yang@uwe.ac.uk,Mobile robot teleoperation and robot learning,MSc Robotics,Intelligent mobile robot control platform based on smart phone,"1) Design a human-computer interface to realize remote control of mobile robot, with acquisition and displayment of visual streams collect by the mounted camera.2) Realize  basic functions of the intelligent car, such as remote steering, automatic tracking, autonomous obstacle avoidance, light seeking and automatic parking.3) Using the car mounted camera to realize face detection and face recognition to identify human use;  to model the environment and to detect accidents,  and to realize patrolling functions;4) Wireless local area network (WLAN) can be used to realize the remote communication between mobile phone and car.",1,UWE,,Ning Wang,UWE,,
Chenguang Yang,Charlie.Yang@uwe.ac.uk,Mobile robot teleoperation and robot learning,MSc Robotics,Mobile phone enabled smart car,"1) Design a Android based app for interactive remote control of a mobile car, e.g., steering and speed control.2) Combine machine vision and machine learning to realize automatic tracking and autonomous obstacle avoidance.3) Develop SLAM for path planning to realize autonomous navigation and positioning4) Create a database for user identity and personalized data storage.platform, design of human-computer interaction interface, remote control of intelligent car end, acquisition and display of image data of car mounted camera, acquisition of sensor data of car end, and Realization of interactive control with car;;2) Realize the basic functions of the intelligent car: such as remote control forward, backward, left and right rotation, automatic tracking and driving, autonomous obstacle avoidance, light seeking and automatic parking, multi-level speed regulation and other functions; the mobile phone terminal uses screen buttons and mobile phone gravity induction to control the car movement and add transportation3) Realize the advanced application of intelligent car: realize autonomous positioning, object detection, path planning; complete the goods handling work, transport the specified items to the designated location at the designated place;4) Feed back the information of the goods and the running environment of the car to the mobile terminal;5) Bluetooth is used to realize the remote communication between mobile phone and car.",0,UWE,,,,,
Hemma Philamore,hemma.philamore@bristol.ac.uk,"Artificial organisms, environmental monitoring, robobts for sustainable food production",Bio-robotics,Robotany â€“ An artificial ecosystem of robots,"Hydroponic growing systems allow for plants to be grown without the use of soil. Typically, systems are layered, with the upper layer holding the plants that have been rooted into a substrate, and the lower layer acting as the water reservoir. Benefits of these systems include increased yields and reduced water consumption compared to conventional farming, as well as allowing plants to be grown in almost any location, and often in the absence of natural light, meaning that currently unusable land can be repurposed. Closed system hydroponics also help to reduce agricultural run-off, which can be very damaging to the environment. As such, hydroponics is being touted as a potential way to move towards more sustainable farming. However, without soil to act as a buffer, a more hands-on approach is often required to maintain a delicate balance of oxygen levels, pH, and fertiliser; tipping too far in any one direction can lead to unsatisfactory yields, damaged roots, or algal blooms. A potential method of both monitoring nutrient levels and ensuring that the system remains in balance involves robotics. An artificial ecosystem of simple robots that live and operate within the hydroponics systems would allow for constant feedback, as well as providing the opportunity to affect changes in an otherwise difficult to access space. This project aims to explore the potential uses of robotics for improving the way that hydroponic systems work and has scope for multiple students to work in parallel on different research topics. Example research themes : â€¢	using novel bio-inspired sensing for navigation of a swimming robot within the tank  â€¢	energy-harvesting from light and biomass to power a robot operating in the hydroponic system   â€¢	development of a self-powered bio-sensor for plant health or nutrient level using microbial fuel cells The project will run alongside an ongoing EPSRC-funded project titled â€˜Robotanyâ€™. There is potential scope to test findings in real hydroponic set-ups, working with industry partners on the project.  ",3,,"[""MSc Robotics"",""MSc Bio-Robotics""]",Elliot Scott,UoB,,
Hemma Philamore,hemma.philamore@bristol.ac.uk,"Swimming robots, simulation, path-planning, environmental monitoring ",,Finding Nemo: Simulating an underwater robot for environmental monitoring,"A major challenge when developing underwater robots is protecting the internal parts of prototype robots, such as electronics and computation hardware, from damage due to water ingress. This can make iterative design and testing an extremely difficult process. Simulation can be a useful tool for developing the robot design prior to testing in an underwater environment.   This project will build on an existing underwater robot, which was developed for environmental monitoring. For the monitoring, the robot is supposed to follow a given set of points, at which measurements will be taken. To try different control and path planning algorithms, which can be used in this scenario, the student will develop a model of the robot within an existing simulation framework. It is suggested to use either UUVSimulator or UWSim in combination with ROS, but this will be ultimately up to the student. Factors that should be considered for the control and path planning are the efficiency and length of the path, as well as the disturbance that is caused by the robot.",1,,"[""MSc Robotics""]",Hendrik Eichhorn,UoB,,
Hamidreza Nemati,Hamidreza.Nemati@uwe.ac.uk,Amphibious Micro Aerial Vehicle; Underwater exploration; Subsea inspection and intervention; Attitude and pose stabilisation;,,Design and Stabilisation of an Amphibious Drone (Underwater Drone),"Recently, different drones must be used for different missions and applications. Therefore, an innovative and cost-effective solution is required to assist the end-user by developing a cross-domain vehicle. This vehicle is able to merge the benefits of operating in both aerial and underwater domains. Attached file is the Loon Copter created by the Embedded Systems Research Laboratory at Oakland University.",1,,"[""MSc Robotics"",""MSc Aerial Robotics""]",,UWE,,
Hamidreza Nemati,Hamidreza.Nemati@uwe.ac.uk,Distributed flight arrays; Modular single-/multi-rotor aerial vehicles; Self-assemble; Attitude and pose stabilisation;,,Design and Stabilisation of Distributed Flight Arrays (DFAs),"Distributed flight array (DFA) is a modular single-propeller aerial robot that has been firstly developed at ETH Zurich by Prof Raffaello Dâ€™Andrea in 2008. Each unit can generate enough thrust to take off but itâ€™s unstable in flight. For flying in the air, each unit can drive autonomously and dock with its peer on the ground. DFA configuration and components are presented in the attachment [1]. In this project, new mechanical chassis design and configuration (feasibility studies) are required using modelling and motion analysis software such as SOLIDWORKS and MSC ADAMS (or ROS).",1,,"[""MSc Robotics"",""MSc Aerial Robotics""]",,UWE,,
Hamidreza Nemati,Hamidreza.Nemati@uwe.ac.uk,Multi-Agent Systems; Cooperative control; Multi-Missile Systems;,,Cooperative Multi-Missile Systems,"Recently, the research on cooperative multi-missile systems (MMS) has attracted more attention and efforts due to the advancement of anti-missile technology. In another words, from the missile point of view, the mission success in the conventional one-to-one engagement scenario will be degraded because a missile can be destroyed by the defence system of the target. However, an effective way is to employ a group of well-organised and low-cost MMS rather than an individual high technology and high cost missile.",1,,"[""MSc Robotics"",""MSc Aerial Robotics""]",,UWE,,
Quan Zhu,quan.zhu@uwe.ac.uk,"dynamic system modelling, analysis, control, and simulation",,Reinforcement control learning algorithm applied to Autonomous Underwater Vehicle (AUV)  in simulation,"Sliding model control and AI are traditionally used control techniques of underwater vehicles .Most of these methods often focused on lower dimensional systems, for instance yaw and surges and constraints other range of possible motions along other dimensions. The implementation of the control of underwater vehicle required a dynamical model of the vehicle movement between initial and target points, which require a navigation problem or high level control. This project would investigate a control systems of an AUV with no explicit model based reinforcement control learning algorithm. The control input would be calculated upon states measurement (or estimated) and reward shaping from the signal to maximise the reward. The project would be in simulation using Matalb Simulink. ",2,,"[""MSc Robotics""]",Prof William Holderbaum (University of Reading),UWE,,
Quan Zhu,quan.zhu@uwe.ac.uk,"dynamic system modelling, analysis, control, and simulation",,Robotics FES for Under-actuated systems,"Underactuated robotics is an emerging research field. The number of control input of the underactuated systems is less than the degree of freedom of the system. It can be for economical reason or constraints due to the nature of the systems. Biped robots may have this possible configurations where the number of possible actuators is restricted to the upper part of the legs while the lower part in independently control. This is the case in rehabilitation engineering where control the muscles of the tights via electrical stimulation. The project will consist to model and control via simulation tools a walking biped robots with the constrains of being under actuated systems, Control methods could range from linear control to deep learning.",2,,"[""MSc Robotics""]",Prof William Holderbaum (University of Reading),UWE,,
Quan Zhu,quan.zhu@uwe.ac.uk,"dynamic system modelling, analysis, control, and simulation",,Autonomous Landing,The project will focus on vision-based control approach to enable autonomous landing of vertical take-off and landing (VTOL) capable unmanned aerial vehicles (UAVs). A simulation tool will show feature of some of the control methods to accomplish the landing task. A control systems using reinforcement control learning algorithm to learn from computer vision data to operate the landing. Through comparison with a gain-scheduled proportional integral derivative (PID) control system is with the vision system and then implemented on a quadrotor-UAV dynamic model in a realistic simulation program. Extensive simulations are conducted to demonstrate the ability of the controller to achieve robust landing. Repeated flight tests could be used for comparison between the algorithms.,2,,"[""MSc Robotics""]",Prof William Holderbaum (University of Reading),UWE,,
Quan Zhu,quan.zhu@uwe.ac.uk,"dynamic system modelling, analysis, control, and simulation",,Mobile robots control via voice activation,"In the near future, the usage of a mobile robot should become a common practice anywhere and a spoken language is a convenient interface for commanding such devices. Therefore, the project intent to develop an interface between human and control. The simulated robotÂ´s movements will be controlled according to the given instructions. Matlab-Simulink will be the starting point of the project but it is expected to use Arduino and embed the methods in a small wheel robot.",2,,"[""MSc Robotics""]",Prof William Holderbaum (University of Reading),UWE,,
Quan Zhu,quan.zhu@uwe.ac.uk,"dynamic system modelling, analysis, control, and simulation",,U-model Based Sliding Mode Control (SMC) to Increase Robustness of Various Robots,"This dissertation research project aims to integrate U-model (UM) design procedure and Sliding Mode Control (SMC) to improve robustness of robots. U-model based control (U-control) is a model-independent control system design approach simplify the design complexity of nonlinear control systems without linearisation.  It bridges the gap between linear and nonlinear system design. Through UM, linear polynomial model-based methodologies, such as pole assignment, can be implemented directly on nonlinear control systems, and that the system performance can be tuned according to actual requirements. However, one remarkable shortage of UM methodology is that it relies heavily on precise system model, which is very hard to obtain. In this case, SMC is considered as its complement to improve the robustness of the system. Therefore, U-model is used to simplify its control design procedure of nonlinear system with a desired transient and steady state linear transfer function of the resulting closed-loop system. Then combining sliding mode control scheme improves the robustness possibly induced from U-model based dynamic inversion. The main objectives of this project include â€¢ propose an integrated methodology of U-model and Sliding Mode Control. â€¢ complete a basic tracking task of a 2-DOF manipulator with disturbance using proposed Methodology. â€¢ analyse the proposed methodology and render a descent evaluation.",2,,"[""MSc Robotics""]",Prof Charlie Yang (UWE),UWE,,
Yaseen Zaidi,yaseen.zaidi@uwe.ac.uk,"Rendezvous, terminal guidance, relative dynamics, Clohessy-Wiltshire-Hill equation, trajectory optimisation, constellation",,Rendezvous of a Refuelling Space Tug with OneWeb Constellation,"The present work has reduced the terminal guidance problem of a single target spacecraft with a chaser spacecraft to 1m accuracy using a genetic algorithm and gradient descent methods for trajectory design. We wish to bring the accuracy to cm using the currently implemented algorithms or the Monte Carlo method. Once achieved, the final aim is to rendezvous one after another with multiple OneWeb spacecraft in a constellation of ~650 and refuel them. ",1,,"[""MSc Aerial Robotics""]",,UWE,,
Yaseen Zaidi,yaseen.zaidi@uwe.ac.uk,"High L/D, radiation, avionics, 3-D printing, drone, payload",,Nukopter,"A high lift-to-drag ratio and copter drone carrying a significant avionics payload for inspection and scanning before personnel move in and for equipment external health monitoring will be designed and 3-D printed. The drone will be built with smart material just in case of a stall or safety abort. The payload is going to be a ZED 3-camera. Images would be sent over a wireless link. Dense integrated avionics would be protected for radiation which would be detected with an on-board dosimeter. The design requirements include facility dimensions, inspection or operator safety, heights, lighting, environmental conditions (temperature, pressure, humidity), etc. The use case of the drone operating environment is extreme conditions, containment buildings, and draft wet cooling towers.",3,,"[""MSc Aerial Robotics""]",Vilius Portapas,UWE,,
Yaseen Zaidi,yaseen.zaidi@uwe.ac.uk,"Object detection, spacecraft integration, mixed reality, HoloLens 2, Azure Services",,"Parts Tracking during Spacecraft Assembly, Integration and Test with HoloLens 2","Industrial partner: Thales Alenia Space. The project was offered last year and excellent results were achieved. Now, we aim to expand the dataset and improve training, detection, continuous object detection, latency, blur, UI, and usability and uniquely identify parts. A further aim is to fully digitise the Assembly, Integration, and Test (AIT) process with holographic support. A big area of interest for AIT across all of Thales Alenia Space is parts tracking. The idea is that during assembly, parts can be automatically tracked either by external cameras or an AR headset as they are placed to record them leaving a store's database and to have a record of exactly where they end up. Putting RFID or QR codes on the parts is the easy solution, but fast and reliable image recognition with HoloLens to determine size as well as the shape would be far better.",1,,"[""MSc Robotics""]",Chris Toomer,UWE,,
Yaseen Zaidi,yaseen.zaidi@uwe.ac.uk,"eVToL, flight profile, digital twin, situational awareness",,eVToL Digital Twin Demonstrator,"Industrial partner: Smart Ports Systems, Neoptera. In the dock2dock project, the current development is a digital flight profile of an electric aircraft between Bristol and Cardiff docks. The digital twin features include equivalent fuel consumption, Traffic collision Avoidance System TAS radar, availability of GPS constellation over the route, and detection of an approaching aircraft. We aim to enhance the air situational awareness capability with an on-board camera, performance characteristics such as cruise airspeed, roll rate, and bank angle, access times, GPS jamming locations, emergency landing and adding realism to the aircraft's fixed antenna pattern when rolling. Communications interference analysis and access to the 5G network will be additional targets. The goal of the digital twin is to support the development of the regulatory framework of the UK Civil Aviation Authority.",1,,"[""MSc Aerial Robotics""]",Vilius Portapas,UWE,,
Hamidreza Nemati,Hamidreza.Nemati@uwe.ac.uk,Orbital debris; Space manipulators;,,Robot Manipulators for Space Debris Removal,"There are various examples of robot applications to assist humans in space. Recently, there is a global concern on the population growth of orbital debris that have the potential to collide and cause massive disruption. However, robotic manipulators can be employed to avoid the collision and catastrophic failure of space missions.",1,,"[""MSc Robotics"",""MSc Bio-Robotics"",""MSc Aerial Robotics""]",,UWE,,
Hamidreza Nemati,Hamidreza.Nemati@uwe.ac.uk,Attitude control; Propellant slosh;,,Spacecraft Attitude Control with Internal Fuel Sloshing,"Propellant slosh during spacecraft manoeuvre, upper-stage separation and orbit injection in partially filled fuel containers may affect the stability of the spacecraft motion or even disintegrates the whole system. This research aims to model and control of propellant slosh dynamics during spacecraft attitude manoeuvre.",1,,"[""MSc Robotics"",""MSc Aerial Robotics""]",,UWE,,
Hamidreza Nemati,Hamidreza.Nemati@uwe.ac.uk,Station-keeping; Libration point orbits; Circular Restricted Three Body Problem;,,Spacecraft Station-Keeping around Libration Point Orbits in the Circular Restricted Three Body Problem (CR3BP),"The problem of spacecraft station-keeping for libration point orbits has received great attention recently for space exploration missions such as ARTEMIS. In this research, an appropriate control method must be derived for spacecraft station-keeping (or formations) near libration points of CR3BP.",1,,"[""MSc Aerial Robotics""]",,UWE,,
Hamidreza Nemati,Hamidreza.Nemati@uwe.ac.uk,Soft-bodied robots; Compliance; State space;,,"Soft Robotics: Novel components, Modelling and Simulation","Compliance in soft robots can allow them to adapt their shapes against objects with unknown and uncertain geometry. Therefore, new class of components are required to deal with various environments. Furthermore, there still exists an open challenge to create an accurate mathematical formulation due to the infinite dimensionality of the robotâ€™s state space.",1,,"[""MSc Robotics"",""MSc Bio-Robotics"",""MSc Aerial Robotics""]",,UWE,,
Hamidreza Nemati,Hamidreza.Nemati@uwe.ac.uk,Soft-bodied robots; Intelligent controller; Harsh environment;,,Soft Robotics: Intelligent Control,"Considerable efforts have been recently dedicated to building soft bodies for robots. However, relatively less attention has been given to the problem of developing their intelligent brains particularly in harsh environments.",1,,"[""MSc Robotics"",""MSc Bio-Robotics"",""MSc Aerial Robotics""]",,UWE,,
Hamidreza Nemati,Hamidreza.Nemati@uwe.ac.uk,Soft robotic ctuators; Young's modulus; Structure stiffness; Measurement noises and biases and drifts;,,Soft Robotics: Noise & Vibration,"Since soft robotic actuators have low Youngâ€™s modulus and low structure stiffness, they may vibrate back and forth drastically once they are excited or unactuated. These undesired oscillations can greatly decrease production efficiency and accuracies in industrial applications. On another front, many intelligent robots utilise commercial off-the-shelf sensors that are noise-, bias- and drift-prone and hence inaccurate. Since these sensors are always part of a control system, measurement noises, biases and drifts can degrade the performance of the controller and may lead to instability. Therefore, suitable algorithms are required to counteract the above problems.",1,,"[""MSc Robotics"",""MSc Bio-Robotics"",""MSc Aerial Robotics""]",,UWE,,
Hamidreza Nemati,Hamidreza.Nemati@uwe.ac.uk,Under-actuated systems; Nonholonomic velocity constraints;,,Stabilisation of Under-actuated Mechanical Systems,"Under-actuated mechanical systems (UMSs) are mechanical control systems in which the number of configuration variables are greater than the controls. Stabilisation of UMS is still an active field of research because of their broad applications in robotics, aerospace and marine vehicles. ",1,,"[""MSc Robotics"",""MSc Bio-Robotics"",""MSc Aerial Robotics""]",,UWE,,
Zhenyu Lu,zhenyu.lu@uwe.ac.uk,"Robot hand, Soft robot, Mechanical design",,New Soft Conjunction Design and Test of Human-Like Robot Hand Links ,"This theme belongs to the mechanical design and soft robot area. Humans use hands for grasping and manipulation thousands of times, and the connection part between hand bones is the key to ensuring the flexibility and smoothness of the operations. Compared with solid linkage, soft conjunction has a good cushioning effect and helps to reduce the frictions during the relative movements of hand links. This project will improve the current robot hand structure to replace the solid conjunction with a soft one and test and compare the differences in performance.",1,,"[""MSc Robotics""]",Chenguang Yang,UWE,,
Zhenyu Lu,zhenyu.lu@uwe.ac.uk,"Robot hand, Variable impedance control",,Improved Variable Impedance Actuator System for Tendon-driven Robot Hand ,Improved Variable Impedance Actuator System for Tendon-driven Robot Hand,1,,"[""MSc Robotics""]",Chenguang Yang,UWE,,
Zhenyu Lu,zhenyu.lu@uwe.ac.uk,"Exoskeleton, Teleoperation",,Exoskeleton Structure Improvement for Free-space Teleoperation ,"The theme belongs to the areas of mechanical design (10%), electronic design (10%), and teleoperation technology (80%). Traditional teleoperation is taken based on the joystick or gesture recognition equipment to acquire the demonstration information, and then accepts the feedback such as force, video for decision in next step. The participant in this project will be provided with a newly designed exoskeleton to improve the hardware performance and then design a software toolkit for completing teleoperation and manipulation through a physical twins system. The application should be familiar with ROS, C++ or Python.",,,"[""MSc Robotics""]",Chenguang Yang,UWE,,
Zhenyu Lu,zhenyu.lu@uwe.ac.uk,"Learning from demonstration, Meta-Learning ",,Robot Primitive Skill Learning from Few-shot Demonstrations based on Meta-Learning ,"The theme belongs to the areas of robotic technology and artificial intelligence. Meta-learning is state-of-the-art technology for learning from multiple few-shot cases but seldom used for robot skill learning. In actuality, the demonstrations of robot manipulation are hard to be acquired directly, so there are lots of distributed demonstrations acquired from various scenes. This project will explore robot skill learning technology from multiple few-shot demonstrations based on Dynamic Motion Primitive and  Meta-Learning. The technology will be verified through the robot operational platform. The applicator should have a basic knowledge of machine learning and be familiar with C++ or Python.",,,"[""MSc Robotics""]",Ning Wang,UWE,,
Zhenyu Lu,zhenyu.lu@uwe.ac.uk,"Robot grasping, Imitation learning, Neural networks",,Robust Robot Primitive Skill Programming Network  for Object Grasping and Manipulation,"The theme belongs to the areas of robotic technology and artificial intelligence. Imitation learning is a modern technology for realizing robots quick programming. After acquiring primitive learning skills, how to analyse the difference and evaluate the manipulation performance to improve the robustness and flexibility of network structure is the research topic of this project. The technology will be verified through the robot operational platform. The applicator is required to have a basic knowledge of machine learning, robot skill learning (e.g. imitation learning) and be familiar with C++, Python or MATLAB.",,,"[""MSc Robotics""]",Ning Wang,UWE,,
Iwona Gajda,Iwona.gajda@uwe.ac.uk,,,,,1,,"[""MSc Robotics""]",,UWE,,
Iwona Gajda,Iwona.gajda@uwe.ac.uk,,,,,1,,"[""MSc Robotics""]",,UWE,,
Anna Chatzimichali,Anna.chatzimichali@uwe.ac.uk,"privacy-sensitive robotics, data rights",,What my robot knows about me and who owns that knowledge: User data rights in service robotics," In the field of social and service robots, user data are crucial in order to design a meaningful connection with the user. The quality of such user data, as well as a clear model of their ownership is also extremely valuable when it comes to designing future features in user interaction with the robot. Such data are the new currency of the digital economy. The rise of inter-connected digital goods and services marked the end of an era of local data storage in user owned equipment. In the new era of remote computing, internet of things, personalised machines and robots, user data are almost always stored in third party remote resources. This shift made ownership of digital assets and data privacy increasingly abstract. However, the landscape of ownership of such user generated data records (or personal data) is unclear. Currently, no organisation has the obligation or the capacity to protect digital personal data, while data protection usually happens only as a result of personal interest. The main idea behind this work is to investigate data right architectures in social/service robots and especially within a collaborative personalisation space. Data is power, but in a collaborative personalised space who really owns the power?",2,,"[""MSc Robotics""]",Anouk van Maris,UWE,,
Anna Chatzimichali,Anna.chatzimichali@uwe.ac.uk,"privacy-sensitive robotics, data rights",,What my robot knows about me and who owns that knowledge: User data rights in service robotics," In the field of social and service robots, user data are crucial in order to design a meaningful connection with the user. The quality of such user data, as well as a clear model of their ownership is also extremely valuable when it comes to designing future features in user interaction with the robot. Such data are the new currency of the digital economy. The rise of inter-connected digital goods and services marked the end of an era of local data storage in user owned equipment. In the new era of remote computing, internet of things, personalised machines and robots, user data are almost always stored in third party remote resources. This shift made ownership of digital assets and data privacy increasingly abstract. However, the landscape of ownership of such user generated data records (or personal data) is unclear. Currently, no organisation has the obligation or the capacity to protect digital personal data, while data protection usually happens only as a result of personal interest. The main idea behind this work is to investigate data right architectures in social/service robots and especially within a collaborative personalisation space. Data is power, but in a collaborative personalised space who really owns the power?",2,,"[""MSc Robotics""]",Anouk van Maris,UWE,,
Anna Chatzimichali,Anna.chatzimichali@uwe.ac.uk,"circular economy, design for disassemembly",,Robots in circular economy: The role of robots and cobots in product disassembly ,"Circular economy and design for disassembly as an emerging trend promise to create a sustainable impact in our world. In the past products were used for a considerable number of years, were frequently repaired and were not discarded easily. The rapid advance of technology, the consecutively more effective manufacturing and the automation of production have led to the insertion of new products in the market. Modern products are enhanced in capabilities, while cheaper than the ones they replace. Assessing the quality of product design from the disassembly point-of-view is emerging as a key issue in end-of-life treatment options of electrical and electronic waste.  Design for Disassembly (DfD) has been developed as a framework for defining disassembly goals, applying specific guidelines, reducing disassembly complexity and evaluating product ease of disassembly in the design phase. However the diassembly process is still in its infancy when it come to automation or the use of robots within it. This project will explore the role of robotics with exisiting DfD frameworks and the role they can play in the circular economy.   ",2,,"[""MSc Robotics""]",,UWE,,
Mark Hansen,mark.hansen@uwe.ac.uk,"Machine vision, machine learning, agritech, reinforcement learning",,Open-set (re-identification) recognition of pigs,"Being able to recognise animals without having to enrol them first is potentially extremely useful for managing welfare. Using our own datasets, and any others available, you will be able to improve your knowledge and experience of deep learning architectures such as siamese networks and triplet loss to provide new insights into the problem.",1,,"[""MSc Robotics""]",,UWE,,
Chenguang Yang,Charlie.Yang@uwe.ac.uk,robot learning,,Primitive Skill Library Building and Learning for Robot Composites Layup though Teleoperation and  Kinesthetic Demonstration,"Composite layup is challenging for robots. A flat fibre-reinforced material that is relatively inextensible along the fibre direction must be draped onto a complex (often doubly curved) mould geometry while retaining desired fibre orientations and avoiding damage. This project will focus on building the primitive skill library and realizing primitive skill learning based on the classification of operational scenes through both teleoperation and  kinesthetic demonstrations. The final driveable contains a library consisting of primitive skills, covering at least three kinds of operational cases.",1,,,Ning Wang,UWE,,
Conor Houghton,conor.houghton@bristol.ac.uk,"neurolinguistics, language games, neuroscience, decision making ",,Language games for language evolution,"Language games - can a collection reinforcement learning agents learn to communicate; in the past attempts to do this using signalling games such as the Lewis signalling game [Lewis 1969] have been bedevilled by the agents `cheating' using non-compositional communication strategies to communicate without developing an effective language. I think, with more powerful computers and better board games, it is time to revisit this! This project would involve reinforcement learning approaches to communication games such as Dixit.",1,,"[""MSc Bio-Robotics""]",,UoB,,
Sabine Hauert,sabine.hauert@bristol.ac.uk,"Swarm, Rewilding",,A Robot Swarm to Assist British Rewilding,"In recent years there have been multiple rewilding projects taking place across the UK. The introduction of beavers, buffalo, pine marten, and other species across the country has had significant positive environmental impact. A key feature of re-wilding in other countries comes from trophic cascade via the introduction of predators; a notable example of this is the effect of wolf reintroduction on the rivers of Yellowstone national park in the USA. In this project, we look to develop a swarm technology to support rewilding in the UK, regulating movement of animals to prevent the predation of livestock, monitoring new species, or mapping the effects of introduced flora and fauna. We expect you to develop a swarm robotic solution for livestock and predator separation, creating a simulation to demonstrate your ideas.",1,,"[""MSc Bio-Robotics""]",James Wilson,UoB,,
Sabine Hauert,sabine.hauert@bristol.ac.uk,"Swarm, Trust, Collective Memory",,Collective Memory for a Trustworthy Swarm,"Understanding swarm behavior is a key element in building trustworthiness and widespread user adoption of swarm technology. By developing effective means of extracting and visualizing swarm information we can create more understandable and more trustworthy swarms. We have recently designed a swarm that is capable of self-monitoring, providing swarm information to a user in a fully distributed manner. To supplement this work, we are looking to create an effective mechanism for distributing memory amongst a swarm. This system will leverage the total memory available to the swarm, rather than just individual agents, while still ensuring that users have access to the data they require in reasonable time. The effective distribution of memory across a swarm should enhance the scalability and provide a simple but powerful method for monitoring swarm activities.",1,,"[""MSc Bio-Robotics""]",James Wilson,UoB,,
Farid Dailami,farid.dailami@uwe.ac.uk,Digital twin,,Digital Twin for a Welding Cell, This project will aim to produce a Digital Twin of a welding cell currently being developed at Roll Royce. The work will entail the development of a model to examine the robot and work handling equipment needed to repair components using the welding process,1,,"[""MSc Robotics""]",,UWE,,
Farid Dailami,farid.dailami@uwe.ac.uk,Mobile robot,,Unitree A1 Dog Surveyor," The aim of this project is to use an Unitree A1 Dog to survey a building site and monitor safety infringements. This work requires both robotics, in particular SLAM and also scene interpretation from a vision system.",1,,"[""MSc Robotics""]",,UWE,,
Farid Dailami,farid.dailami@uwe.ac.uk,Digital twin,, Digital twin of a motor and disc assembly," The aim of the project is to develop a digital twin, where the loop between the model and the real system is closed and various â€˜what ifâ€™ type analysis can be carried out.",1,,"[""MSc Robotics""]",,UWE,,
Farid Dailami,farid.dailami@uwe.ac.uk,Digital twin,,Modelling of a cable robot," â€¢	Modelling of a cable robot Develop a model of a cable robot and simulate its performance in performing a number of industrial processes requiring precision motion.   ",1,,"[""MSc Robotics""]",,UWE,,
Paul Bremner,paul2.bremner@uwe.ac.uk,"HRI, Teleoperation, Sonification",,Data sonification for robot teleoperation,"In data sonification data is mapped to parameters of different sounds so that they can be used to â€˜displayâ€™ the data. It has advantages over visual display of data as previous research has shown that multisensory integration of vision with sound can improve an operator's awareness during high visual load tasks. Importantly, the human auditory system has a high temporal resolution, wide bandwidth, and can localise and isolate concurrent audio streams. In this project we propose using data sonification of operation critical data for teleoperation of a robot arm. It builds on existing work of sonification in VR, and utilises our existing leader-follower teleoperation system. This project will involve programming for ROS and UNITY (building on existing work so prior in depth knowledge of these environments is an advantage but not required), and designing and executing a user study to evaluate the utility of sonified data.",1,,"[""MSc Robotics""]",Alex Smith,UWE,,
Paul Bremner,paul2.bremner@uwe.ac.uk,"HRI, Teleoperation, Multi-modal communication",,Automated gesturing for a telepresence robot,"A chief advantage of telepresence robots is their ability to improve operator presence and interaction quality. However, a common feature of human communication that is not easily relayed via a telepresence robot is conversational gesture. This project aims to investigate whether conversational gestures might be autonomously generated from an operators speech, such that interaction quality is improved. The project will involve programming a gesture generation system (likely in Python) for a NAO robot, including a method to predict gesture frequency from speech, and design and execution of a user study to evaluate it.",1,,"[""MSc Robotics""]",,UWE,,
Dandan Zhang,ye21623@bristol.ac.uk,"Robot learning ( Machine Learning and Deep Learning for Robotic Manipulation/Computer Vision), Teleoperation, Tactile Robotics, Human-Robot Shared Control, Human-Robot Interaction, Multi-Sensor Fusion",,Reinforcement Learning for Robotic Manipulation Based on Multi-Sensor Fusion,"For sensing techniques used for robotic dexterous manipulation, there are two primary modalities: vision and tactile. The robot can be guided to approach the target objects based on visual feedback, while tactile feedback can provide useful information of interaction between objects and the environment. These two modalities are complementary to each other for contact-rich tasks.  To this end, this project aims to explore multimodal representation learning, which could be a useful tool for developing a robust and task-related representation to facilitate reinforcement learning with high efficiency. ",1,,"[""MSc Bio-Robotics""]",Nathan Lepoa,UoB,Pengyuan Wei ,Yes
Dandan Zhang,ye21623@bristol.ac.uk,"Robotic Hand Design, Tactile Sensing",,Design of a two-finger robotic hand with tactile feedback,"This project aims to develop a two-finger robotic hand, which can be used to grasp deformable target objects such as plastic bottles with various shapes. The robotic hand should integrate tactile sensors to provide feedback to the controller, which paves a way for the development of an adaptive control algorithm to determine the best grasping strategy.",1,,"[""MSc Robotics""]",Nathan Lepoa,UoB,Fengrui Zhang,Yes
Dandan Zhang,ye21623@bristol.ac.uk,"Soft Robotics, Actuator, Control, In-Hand Manipulation",,Soft robotic hand for in-hand manipulation,"This project aims to develop a soft robotic hand and demonstrate its potential for in-hand manipulation. In-hand manipulation involves manipulating an object within one hand. It is a vitally important capability for robots to accomplish real-world tasks. Therefore, it is worthwhile to investigate robotic dexterous in-hand manipulation to reconfigure an object. Soft robotic hands can enable robots to grasp delicate or soft objects of varying shape, size, and pose without explicit knowledge, and is promising for potential applications such as manipulating eggs or fruits etc. Machine learning approaches can be explored to mitigate the need of complex planning and control for in-hand manipulation when using a soft robotic hand with dexterous fingers.",1,,"[""MSc Robotics"",""MSc Bio-Robotics""]",Jonathan Rossiter,UoB,,
Dandan Zhang,ye21623@bristol.ac.uk,"Machine Learning, Deep Learning, Computer Vision, Simulation",,Surgical Gesture Segmentation and Recognition for Medical Robotic Applications,"Minimally invasive surgery mainly consists of the execution of a series of specific sub-tasks, which can be further decomposed into basic gestures or contexts. As a prerequisite of autonomic operation, surgical gesture recognition can assist motion planning and decision-making, construct context-aware knowledge to improve the surgical robot control quality, which may lead to better clinical outcomes. This project aims to investigate Bayesian Inference and explainable machine learning approaches for surgical gesture segmentation and recognition across multiple robotic platforms. The student is expected to have basic knowledge of machine learning and is familiar with Python.",1,,"[""MSc Robotics"",""MSc Bio-Robotics""]",Weiru Liu,UoB,,
Dandan Zhang,ye21623@bristol.ac.uk,"Human-Robot Interaction, Cooperative Control, Human Intention Recognition, Medical Robotics",,Human-Robot Cooperative Control for Medical Robotics,"Teleoperation is widely used for medical robotic platforms. To ensure seamless and intuitive control, an optimized leader-follower control model should be built to assist the operator in a cooperative manner. The operator can retain precise control when conducting delicate or complex manipulation, while an accelerated movement to the next distant target can be achieved. Moreover, haptic guidance should be included in the control framework. Learning from expert demonstration algorithms can be explored to obtain a pre-trained model, which can be used to provide the haptic guidance signals for instructing trainees during teleoperation or supervising novice surgeons to enhance the surgical operation skills. The student is expected to have basic knowledge of machine learning and is familiar with Python/C++ as well as simulation.",1,,"[""MSc Robotics"",""MSc Bio-Robotics""]",Chenguang Yang,UoB,,
Dandan Zhang,ye21623@bristol.ac.uk," Deep Learning, Computer Vision, Robotic Manipulation",,Sim-to-Real Transfer Learning for Robotic Manipulation,"Training a deep learning model for robotic manipulator to locate and grasp the target object is notoriously costly and time consuming. It requires a large amount of data, which is not reasonable for most of the real-world applications. This project aims to train the deep learning model in a simulation environment and implement sim-to-real transfer learning technique to transfer the pre-trained model from the simulator to the physical environment. This project will have collaboration with industry.",1,,"[""MSc Robotics"",""MSc Bio-Robotics""]","Nathan Lepora, Daniel Freer (external)",UoB,,
Dandan Zhang,ye21623@bristol.ac.uk,"robot learning, control, machine vision",,Robotic Skill Learning for Cooking,"With advances in the field of robotic manipulation, machine learning and sensing, intelligent robots are expected to assist humans in kitchens and restaurants. This project aims to develop assistive robots for cooking, which is envisioned to replicate human skills in order to reduce the burden of the cooking process. ",1,,"[""MSc Robotics"",""MSc Bio-Robotics""]",Virginia Ruiz Garate,UoB,,
Nathan Lepora,n.lepora@bristol.ac.uk,"Robot learning, dexterous manipulation, tactile sensing, deep learning, reinforcement learning, haptics",,Next generation biomimetic optical tactile sensing,Co-created proposal with Xuyang Zhang. Not available for other MSc students.,,,"[""MSc Robotics""]",,UoB,,
Arthur Richards,arthur.richards@bristol.ac.uk,Navigation; Control; Estimation,,Robot Odometry using Sparse LIDAR ,"There have been awesome breakthroughs in SLAM, where dense sensors like cameras, depth cameras or LIDARs are used to identify and track features in the world and hence track motion.  However, those systems have extensive size, weight and power (SWaP) needs.  This project will explore a navigation idea using just a few lightweight narrow-beam rangefinders, e.g. LIDARs, which have much reduced SWaP needs.  The key is to exploit the natural orthogonal nature of most built-environments, i.e. that most rooms are cuboids.  This observation reduces the navigation problem to one of fault-tolerant estimation, forming a set of hypotheses about what each rangefinder is detecting: north-south wall, east-west wall, ceiling, or nothing useful.  The project will involve a mix of analysis, simulation and hardware experiments to suit individual interests.  It will demand good software skills plus a strong background in estimation or a related topic: sensor fusion, control, dynamics, etc.  As it will be easier to start in 2D, the initial scenario will be based on a rover. ",1,,"[""MSc Robotics"",""MSc Aerial Robotics""]",Mickey Li,UoB,,No
Arthur Richards,arthur.richards@bristol.ac.uk,Multi-agent; Drones; Traffic Management,,Behavior-based modelling and simulation for streaming drones,"This topic is focusing on scheduling the arrival drones by using the pre-set sequencing lines. This system is particularly useful for the crowded landing situation. The lines can be designed straight or curve but they should not be unique. Some of the key points include: how to design the sequencing lines; where to set the merge point; how the new arrival drones merge the exist sequence. To model this sequence system for arrival drones, some behavior-based concepts (e.g., behavior tree, finite state machine) can be used as the design basis. In this study, all the arrival drones can use the same behavior-based models but their control models may be different: a behavior-based controller or decentralized control without a controller. The streaming-drone system can be modelled by programming codes. An alternative way is to use the multi-agent platforms, e.g. Anylogic, Unity3D, which provide friendly functions to implement behavior modeling, state transition, message transmission, and data collection.",1,,"[""MSc Aerial Robotics""]",Yuan Gao; Hirad Goudarzi,UoB,,No
Jiseon You,jiseon.you@uwe.ac.uk,"microbial fuel cell, dynamic reconfiguration, electrical signal, electronics, programming",,Speaking microbial language,"A certain type of microorganisms called electrochemically active bacteria, responses to external electrical load. Therefore, by changing the external load, their responding signal (i.e. electrical current) related to the change can be observed. In this project, the microbial language is translated into electronic signals to help us understand the world of microorganisms. Students are expected to build an electronic controller with built-in function of dynamic reconfiguration of electrical connection. ",2,,"[""MSc Robotics""]",,UWE,,No
Jiseon You,jiseon.you@uwe.ac.uk,"microbial fuel cell, low power actuation, artifical life, energy harvesting",,"Eating, sensing, dying like a beetle ","Beetles (; Coleoptera) are the most common insects in the world. They interact with their ecosystems in several ways: beetles often feed on plants and fungi, break down animal and plant debris, and eat other invertebrates. In this project, we want to create a â€˜livingâ€™ robot beetle that can break down organic substance, sense its surroundings, move as needed, and eventually complete its life then be decomposed by nature. ",2,,"[""MSc Robotics""]",,UWE,,No
Jiseon You,jiseon.you@uwe.ac.uk,"microbial fuel cell, artifical life, bio-sensing, electrochemistry",,Biological robotic tongue,"In this project, students are expected to build biological robotic tongue using the microbial fuel cell (MFC) technology. MFCs convert chemical energy locked inside organic matters into electricity. Their electrical output can be affected by several factors, including the properties of organic feedstock. The robot tongue will detect certain changes in feedstock, such as concentration change and inflow of unwanted substances. ",1,,"[""MSc Robotics""]",,UWE,,No
Virginia Ruiz Garate,virginia.ruizgarate@uwe.ac.uk,"Rehabilitation, Robotics",,Design of an interface for lower-limb rehabilitation using the Franka arm,,1,,"[""MSc Robotics"",""MSc Bio-Robotics""]",,UWE,,No
Virginia Ruiz Garate,virginia.ruizgarate@uwe.ac.uk,"Rehabilitation, Robotics",,Upper-limb rehabilitation using Franka robotic arm,,,,"[""MSc Robotics"",""MSc Bio-Robotics""]",Dan Withney,UWE,,No
Amir Bolouri,amir.bolouri@brl.ac.k,meta-materials,,Self-powered pH-responsive mechanical meta-materials,"The aim is to develop 4D printing of pH-responsive structures that work with pH-responsive polymer gel actuators. In general, these gels show limited actuations and work capacity from the swollen to the unswollen states. By combining multi-material 3D printing and advanced geometrical modelling, we will develop new, bio-inspired actuation mechanics and 3D architectures to transform the small deformation in pH-responsive gels into a large displacement. This will produce pH-responsive 4D soft structures.",2,,"[""MSc Robotics""]",,UWE,,No
Nathan Lepora,n.lepora@bristol.ac.uk,"machine learning, human-robot interaction, force sensing, grasping",,Tactile-based learning for human-robot interaction,"Robot interaction with the environment and humans highly depends on force and energy exchange. Being able to accurately estimate the interaction forces is then essential. This project will focus on building and comparing force/torque models from an optical tactile sensor. Applications can potentially include robot grasping and manipulation or physical human-robot interactions. Prior Python knowledge is essential. During the project, the student will need to become familiar with machine learning libraries and possibly CAD software.",1,,"[""MSc Robotics""]",Efi Psomopoulou,UoB,,No
Jonathan Rossiter,jonathan.rossiter@bristol.ac.uk,"Mechanical Metamaterial, Soft Robotic",,Mechanical Metamaterials for Soft Robots,"Mechanical metamaterials exhibit properties not present in natural matter; therefore, they provide much broader design domain and capabilities than conventional materials. Some of these properties such as negative Poisson's ratio and negative stiffness are among those that can be realized using soft matter. Having soft meta structures can benefit applications of soft robotic such as grasping, gripping and locomotion in different operations like handling and packaging, search and rescue, transport, medical and health care, etc. This project is aiming at considering the design, analysis, and prototyping of soft robotic structures/mechanisms using mechanical metamaterials. The scope of the project is broad and the candidate will have the chance to delve into the details further and focus on application of interest. The project will be executed within the soft lab at the BRL and training for the use of simulation software and manufacturing equipment will be provided. The candidate will also benefit from the state of the art testing and manufacturing facilities at the BRL.",1,,"[""MSc Robotics"",""MSc Bio-Robotics"",""MSc Aerial Robotics""]",Mohammad Naghavi Zadeh,UoB,,No
Mohammad Naghavi Zadeh,m.naghavizadeh@bristol.ac.uk,"Mechanical Metamaterial, Soft Robotic",,Mechanical Metamaterials for Soft Robots,"Mechanical metamaterials exhibit properties not present in natural matter; therefore, they provide much broader design domain and capabilities than conventional materials. Some of these properties such as negative Poisson's ratio and negative stiffness are among those that can be realized using soft matter. Having soft meta structures can benefit applications of soft robotic such as grasping, gripping and locomotion in different operations like handling and packaging, search and rescue, transport, medical and health care, etc. This project is aiming at considering the design, analysis, and prototyping of soft robotic structures/mechanisms using mechanical metamaterials. The scope of the project is broad and the candidate will have the chance to delve into the details further and focus on application of interest. The project will be executed within the soft lab at the BRL and training for the use of simulation software and manufacturing equipment will be provided. The candidate will also benefit from the state of the art testing and manufacturing facilities at the BRL.",1,,"[""MSc Robotics"",""MSc Bio-Robotics"",""MSc Aerial Robotics""]",Jonathan Rossiter,UoB,,No
Jonathan Rossiter,jonathan.rossiter@bristol.ac.uk,"soft robotics, pneumatic actuator, Bubble Artificial Muscle, human assistance",,Development of fully soft Bubble Artificial Muscles to create an assistive device for human body motion,"Bubble artificial muscle (BAM) is a flexible, lightweight, pneumatic-driven actuator created for human-body-assist applications. It can be customised to deliver either high contraction or high tension, and any designs can be optimised to maximise their actuation performance. The BAM was previously used to perform lower limbsâ€™ activities, such as knee flexion for walking [1] and knee extension for sit-to-stand transition [2]. However, the BAM requires rigid rings to configurate the actuator shape and produce contractile motion, which possibly leads to human injuries due to rigid components. This project will explore a new approach to fabricate the BAM purely made from fabric materials without additional rings, for example, by creating uniform folds on material using a heat-sealing method to replace rings. This will result in a 100% soft, flexible fabric-based actuator, which causes the BAMs to be more user-friendly and safer. Reference: [1] https://ieeexplore.ieee.org/abstract/document/8404950 [2] https://www.liebertpub.com/doi/full/10.1089/soro.2019.0157",1,,"[""MSc Robotics"",""MSc Bio-Robotics"",""MSc Aerial Robotics""]","Richard Suphapol Diteesawat, Nahian Rahman",UoB,,No
Jonathan Rossiter,jonathan.rossiter@bristol.ac.uk,"soft robotics, pneumatic actuator, 3D structure, morphological computation",,Exploring designs and patterns of 2D pneumatic actuator for various robotic applications,"Pneumatic actuators have been widely used in robotic fields over several decades thanks to their inherent flexibility, lightweight, high force-to-weight ratio, and simple power source. This project will explore different designs or patterns of pneumatic actuators made of 2D fabric material. When inflating the fabricated 2D fabrics to form pneumatic actuators, different 3D structures and actuation behaviours occur. Combining or connecting different 2D patterns together can result in useful 3D structures, for example, [1]. This concept can also include morphological computation into a structure, meaning that the actuation control is transmitted to the actuator structure, and it can passively change its shape or actuation behaviour by very simple inputs. The outcome of this project can widely benefit robotic fields, such as a medical robot, a robotic manipulator, a locomotion robot, etc.  Reference: [1] https://dl.acm.org/doi/abs/10.1145/2984511.2984520 ",1,,"[""MSc Robotics"",""MSc Bio-Robotics"",""MSc Aerial Robotics""]","Richard Suphapol Diteesawat, Nahian Rahman",UoB,,No
Jonathan Rossiter,jonathan.rossiter@bristol.ac.uk,"soft robotic, electroactive, electrostatic, variable stiffness, structure, origami, metamaterial",,Rapid stiffening capability of flexible 2D and 3D electroactive structures,"This project is to create a stiffening structure by the mean of electrostatic actuation [1]. The concept of an instantly stiffening capability on 2D or 3D structure using electrical power source is intriguing and will be very useful for wide robotic applications: general soft robotics, locomotion robots, medical applications, etc. This project will initially investigate the electroadhension effect of two parallel conductive plates, followed by developing actuators with different patterns or shapes in 2D or 3D. The initial actuator prototype can be a ribbon-like shape. The achievement of this project will lead to a flexible actuator which can be easily deformed to any shapes by external load inputs and can maintain its shape when the electrical power source is supplying.  Reference:  [1] https://ieeexplore.ieee.org/document/8613892",1,,"[""MSc Robotics"",""MSc Bio-Robotics"",""MSc Aerial Robotics""]","Richard Suphapol Diteesawat, Nahian Rahman",UoB,,No
Jonathan Rossiter,jonathan.rossiter@bristol.ac.uk,"soft robotic, tendon-driven structure, flexible steerable system, variable stiffness",,Tendon-driven stiffening structure,"This project will investigate various mechanical designs that enhance the stiffening of a tendon-driven flexible structure at a given configuration. Tendon-driven actuators are quite common and have been explored in robotics (e.g. medical catheter [1], teleoperation, gripper) over several decades, enabling their ability to steer and bend in different planes, etc. Often, they can be under-actuated and provide a simple and low-cost solution for various applications. However, it is difficult for the tendon-driven structure to hold a certain configuration or state in its workspace. In this study, several tendon routing mechanisms (exploiting 3D printing), tensegrity, and auxetic structures will be explored to stiffen the structure at a given instance by activating a tendon actuation. Once a suitable design is obtained, a further investigation to reduce friction, hysteresis effect and coupling (between proximal and distal) effect will be conducted.  Reference: [1] Y. Kim, S. S. Cheng, M. Diakite, R. P. Gullapalli, J. M. Simard and J. P. Desai, ""Toward the Development of a Flexible Mesoscale MRI-Compatible Neurosurgical Continuum Robot,"" in IEEE Transactions on Robotics, vol. 33, no. 6, pp. 1386-1397, Dec. 2017, doi: 10.1109/TRO.2017.2719035.",1,,"[""MSc Robotics"",""MSc Bio-Robotics"",""MSc Aerial Robotics""]","Nahian Rahman, Richard Suphapol Diteesawat",UoB,,No
Jonathan Rossiter,jonathan.rossiter@bristol.ac.uk,"soft robotic, bistable mechanism, bistable structure",,Bistable soft structure inspired from bistable mechanism,"Bistable mechanisms [1] consist of two stable states that can be switched between two different states when some condition(s) is met. In most bistable structures, force is applied to obtain the shift between the states. These structures are useful, and many robots exploit these to obtain some features, such as locking and stiffening features. Having this inspiration from rigid robots, this study will develop semi-rigid and soft bistable structures that are potentially be used as soft-lock, soft-brake, and soft-stiffening structures. For example, these mechanisms can benefit a soft locomoting robot which can change its motion patterns when entering different environments, or a wearable device which can alter assistances at different body postures.  Reference: [1] https://tinyurl.com/yckw84ma",1,,"[""MSc Robotics"",""MSc Bio-Robotics"",""MSc Aerial Robotics""]","Nahian Rahman, Richard Suphapol Diteesawat",UoB,,No
Jonathan Rossiter,Jonathan.Rossiter@bristol.ac.uk,"Visuo-Tactile Sensor, Artificial Intelligence, Adaptive Morphology",,Intelligent Visuo-Tactile Robotic Skin with Adaptive Morphology,"Touch (tactile) sensing helps robots to achieve rich information about the environment (E.g., hardness) during their interactions [1]. In principle, stimuli are first mediated by tactile sensors before they would be further processed for decision making by Central Neural System (CNS). In this perspective, the morphology of sensors is of great importance by affecting the characteristics and property of the sensor [2-3]. A tactile sensor with an optimized, or adaptive morphology can not only improve the performance of perception under different circumstances, but also reduce the cost of computation. For example, in human, the different density of tactile sensing elements (mechanoreceptors) throughout the hand (denser in the fingertips and sparser elsewhere) results in different receptive fields and sensitivities. This ensures that our brain can focus more on processing data from those more important areas (fingertips), thereby reducing the computational burden. Skinflow [4] is a visuo-tactile sensor developed in our lab (SoftLab, Bristol Robotics Laboratory). While it was demonstrated successfully in a few tasks such as shape reconstruction, its morphology is not yet optimized. This project will seek to optimize the morphology of Skinflow making it adaptive and further demonstrate the effectiveness of such design in a range of robotic tasks boosted by prevailing artificial intelligence techniques. Specifically, the student will: 1.	Design and fabricate the Skinflow sensor with an adaptive morphology. 2.	Design experimental setup to characterize the developed sensor. 3.	Developed techniques based on analytical modelling and machine learning to demonstrate the effectiveness of the design in robotic applications, e.g., shape classification. Potential candidate is expected to have a background of mechanical engineering, information science, Computer science and related disciplines, with enthusiasm for research and investigating new area. Preferred skills include 3D modelling, programming (Python, MATLAB, etc), and Finite Element Method (FEM) modelling, etc.   Reference [1] Q. Li, et al, â€œA Review of Tactile Information: Perception and Action Through Touchâ€ù, IEEE Traction on Robotics, 2020. [2] A. B. Vallbo, et al, â€œProperties of Cutaneous Mechanoreceptors in the Human Hand Related to Touch Sensationâ€ù, Human Neurobiology, 1984. [3] F. Iida, et al, â€œAdaptation of Sensor Morphology: An Integrative View of Perception from Biologically Inspired Robotics Perspectiveâ€ù, Interface, 2016.  [4] G. Soter, et al, â€œSkinflow: A Soft Robotic Skin Based on Fluidic Transmissionâ€ù, Proceeding of IEEE International Conference on Soft Robotics, 2019.",1,,"[""MSc Robotics"",""MSc Bio-Robotics"",""MSc Aerial Robotics""]",Qiukai Qi,UoB,,No
Helmut Hauser,helmut.hauser@bristol.ac.uk,"simulation, locomotion, soft robotics",,Dynamic Motion Primitive realisation with mechanical springs for effective locomotion,"Biological system are using central pattern generators (CPG) to produce rhythmic behaviours like locomotion. Based on this principle Isjpeert et al. [1] proposed a clever learning framework called Dynamic Movement Primitives (DMP). At its basis it uses an abstract limit cycles and superimposes nonlinear function to learn rhythmic target trajectories.  This project will explore in simulation the exploitation of physical springs as basis for DMPs. The project can potentially exapnded to implement the results in a real robot. Requirements: Programming knowledge of Python, understanding nonlinear dynamical systems  [1] https://link.springer.com/chapter/10.1007/11008941_60",1,,"[""MSc Robotics"",""MSc Bio-Robotics""]",,UoB,,No
Helmut Hauser,helmut.hauser@bristol.ac.uk,"morphological computation, information theory",,Exploitation of Morphological Features with Preditive Information Maximisation,"It has been shown that Predictive Information Maximisation can be used  to exploited existing complex dynamics to obtain a coordinated behaviour like locomotion, e.g. [1].  In addition, it has been demonstrated that simple compliant systems can exhibit surprisingly complex dynamics that can be exploited for computation and control [2]. The project combines both observations and explores systematically in simulation how predictive information maximisation can be used to find interesting and useful locomotion gaits in compliant robots. The project can be extended to implement the findings in a real robot. Requirements: Programming knowledge of Python, interest in Machine Learning  [1] 1. Martius, G., Jahn, L., Hauser, H. & Hafner, V. Self-exploration of the Stumpy Robot with Predictive Information Maximization. in From Animals to Animats 13 (eds. del Pobil, A. P. et al.) 8575, 32â€“42 (Springer International Publishing, 2014).  [2] Hauser, H.; Ijspeert, A.; FÃ_chslin, R.; Pfeifer, R. & Maass, W. ""Towards a theoretical foundation for morphological computation with compliant bodies"" Biological Cybernetics, Springer Berlin / Heidelberg, 2011, 105, 355-370  https://link.springer.com/article/10.1007/s00422-012-0471-0",,,"[""MSc Robotics"",""MSc Bio-Robotics""]",,UoB,,No
Virginia Ruiz Garate,,,,Remote control of house appliances,,1,,"[""MSc Robotics"",""MSc Bio-Robotics""]",Emanuel Nunez-Sardinha,UWE,,No
Jonathan Rossiter,Jonathan.Rossiter@bristol.ac.uk,Soft Robotics Medical,,Phonetic alphabet generation with Soft Structures,"People can readily converse and spare no thought to how they form the words they are saying using their mouth. The oral cavity is a complex soft structure with a mix of static semi-rigid surfaces, soft tissues, and actuating muscles. The tongue is a muscular hydrostat that enables the shaping of many of the phonetic sounds we produce. To formulate words the tongue, lips and surfaces need to dynamically interact in concert. This project will aim to develop a simulator to generate individual phonics. Some modelling and real-world simulators have been produced with limited success. We want to take this further and use state-of-art soft actuators to mimic one of Natureâ€™s greatest tools.",1,,"[""MSc Robotics""]",Andrew Hinitt,UoB,,No
Jonathan Rossiter,Jonathan.Rossiter@bristol.ac.uk,"Soft Robotics, Medical, Tunnelling",,Peristaltic Robot for Debris Clearance,Removal of debris is a key process in robotic systems (from medical to industrial). Soft robots are of particular interest for tunnelling applications due to their ability to adapt and avoid obstacles in ways current methods cannot. In a tunneling robot debris must be removed to avoid jamming and limiting the tunnelling capability. This has parallels in Nature with tunnelling animals (mammals and invertebrates).  One possible method of clearing debris is through peristalsis - a series of wave-like contractions that propagate down a body. This action is found within the human digestive tract and for locomotion in worms. This project aims to develop a soft system to remove the debris formed by a tunnelling robot through a peristaltic action.,1,,"[""MSc Robotics""]",Keren Yue,UoB,,No
Manuel Giuliani/Arthur Richards,manuel.giuliani@uwe.ac.uk,"marsupial robot, UAV, mobile robot, coverage planning",,Coverage path planning of a marsupial UAV-ground robot," Abstract: The project proposes to use a UAV tethered to a ground robot (preferably a wheeled mobile robot like the turtlebots) for inspecting a nuclear decommissioning plant. It could be tethered physically or virtually. For example, the battery issue of the UAV can be dealt with using a physical cable from the ground robot. Or formation controller can be used as a virtual tether between the robots.  Some areas in the environment like a small tunnel can be explored only by the ground robot, whereas over-bridges can be explored by the UAV only and other areas by both the robots. We want to map/inspect/coverage plan the given environment with this setup.  Research Questions: The student can come up with their own questions based on the area they want to explore. Some of the questions/expected tasks can be: Setting up the marsupial system - either virtually or physically. Localizing the UAV based on the ground robot system without GPS. The UAV can create a 2.5D map using the camera and the ground robot can create a 2D map based on its Lidar for navigation - possible map merging? The robots can do coverage path planning for the given area. How many marsupial robots are needed to do coverage planning/mapping for the given area?https://www.wired.com/video/watch/marsupial-robot  ",2,,"[""MSc Robotics"",""MSc Aerial Robotics""]",Jennifer David,UWE,,No
Chanelle Lee,c.l.lee@bristol.ac.uk,"multi-agent systems, decision making, swarm robotics",,Cat Swarm Optimization in Swarm Robotics,"Cat Swarm Optimization (CSO) is inspired by the behaviours of cats and was originally invented by Chu et al. 2006. Often cats appear to be lazy and spend much of their time resting. However, in this state they remain aware of their surroundings and once they identify a target they pounce. CSO combines both these seeking and tracking modes. This project proposes using Cat Swarm Optimization in a multi-robot system to complete a foraging task. We predict that CSO will minimise energy usage  - an important consideration in scenarios where regular recharging might be difficult. This project would suit a student looking for a balance of theoretical work and programming simulations. It will involve writing large scale simulations in python (or Matlab). Extensions to the project could include using more realistic robotic simulation software such as V-rep.",1,,"[""MSc Robotics"",""MSc Bio-Robotics""]",,UoB,,No
Manuel Giuliani,manuel.giuliani@uwe.ac.uk,"Haptic feedback, multi-robot teams, human-in-the-loop multirobot teams",,Evaluating the use of haptic feedback modality for human-in-the-loop multirobot teams,"Haptic feedback modalities have been employed for robot tele-operation to allow effective robot tele-operation. It may be used to provide force feedback or other measured sensor parameters via sensory substitution. Where a team of heterogenous robots are used to carry out tasks, say for nuclear decommissioning, the introduction of a human tele-operator may improve the efficiency with which the tasks are carried out. The tele-operator may be able to take control of any of the robots to carry out a task. This project proposes the use of a wrist-worn haptic feedback device to provide information about the measured parameters to the tele-operator (via sensory substitution) when the tele-operator takes manual control of a robot. Knowledge of C, C++ or Python programming languages will be beneficial. A user study will be required to evaluate the usability of the haptic feedback modality.",2,,"[""MSc Robotics""]",Joseph Bolarinwa,UWE,,No
Manuel Giuliani,manuel.giuliani@uwe.ac.uk,"Multirobot teams, Human intervention, ",,Determining human intervention for multirobot decision making,"Several decisions are made when a team of heterogenous robots carry out tasks. The scenario changes when a human tele-operator is introduced into the setup. The tele-operator may be able to intervene at different stages of the task to improve the efficiency with which the team of heterogenous robots carry out the task. This project proposes a user study to investigate the need for human intervention, types of interventions and how different tele-operators may perceive the need for intervention. This project may be carried out in simulation or real-world implementation. Knowledge of python or C++ programming languages and ROS will be an advantage. ",2,,"[""MSc Robotics""]",Joseph Bolarinwa,UWE,,No
Paul Bremner,paul2.bremner@uwe.ac.uk,"HRI, Social Interaction",,Robot companions,"Many visions of the future feature people living with robot companions, but how do we get there?  Knowing how people are affected by interactions with a robot will be an essential part of the successful emergence of this future.     The aim of this project is to explore how people interact with, and perceive a robot companion with a focus on how emotions can be expressed by a robot, and what effect this has on people. The project will include developing behaviours for the Vector robot using Python and Raspberry Pi.     There are multiple possible lines of investigation to suit your interests/ expertise. Some example research areas your project could explore are:  - how ethical is it for robots to show emotions without actually feeling them?  - how well do people recognise and respond to robot emotion when they are not expecting it?  - how do robot emotions affect the mood of people interacting with the robot?",1,,"[""MSc Robotics""]",Joe Daly,UWE,,No
Wenhao Zhang,wenhao.zhang@uwe.ac.uk,computer vision; deep learning; HCI,,Assessment of human-computer interaction using vision-based behavioural cues,"When actively or passively interact with a computer, a human user might exhibit different behaviours via head movements and eye movements which can indicate the state of an interaction. For example, frequent head rotations and eye movements may be signs for ineffective human-robot communication (active interaction); and frequent eye blinks of a driver might indicate drowsiness (passive interaction). This project aims to use a deep learning model to estimate head poses, eye centre positions, and eye openness from images and videos in the context of HCI assessments.",1,,"[""MSc Robotics""]",,UWE,Li Lyu,Yes
Paul O'Dowd,paul.odowd@bristol.ac.uk,"swarm robotics, evolutionary robotics, evolutionary algorithms, mobile robotics, educational robotics, artificial intelligence, artificial creativity, embedded systems",,Effect of Spatial Density on Swarm Problem Solving,"Swarm robotic systems are intended to utilise hundreds, thousands or larger numbers of robots working cooperatively. Swarm robotic systems are unusual because they specify that a centralised control scheme should not be used (e.g., no hierarchy, central server or database) . Swarm robotic systems are interesting because they rely on relatively simple local communication between robots as an alternative to centralised control.  Robots are also physical devices, and therefore always occupy mutually exclusive space, and they must navigate around one another.  In these terms, a swarm of robots can be considered as a dynamic network topology - all the robots in the swarm cannot be fully connected to one another, and the nodes of the network are free to move and alter their connectivity.  The aim of this project is to model how the mobility of swarm robots effect the performance of a dynamic network topology.   To assess the performance of the network topology a collective problem is required for the swarm.  This project will implement a distributed evolutionary algorithm (EA) to operate across a swarm of robots.   The study will initially benchmark the performance of the distributed EA on known fixed network topologies common to computer science, such as fully-connected, ring, star and hypercube connectivity. Then, a comparison will be made to a swarm of robots running the same distributed algorithm.  The swarm will be experimentally validated across different degrees of robot mobility.  As an outcome of this research, it should be possible to make recommendations on the degree of mobility (or spatial density) of swarms of robots when communication underpins collective problem solving.   This project will involve both simulation and real robots, with a swarm of Pololu 3Pi+ robots fitted with Infra-red communication as an available candidate.",1,,"[""MSc Robotics"",""MSc Aerial Robotics""]",,UoB,,No
Paul O'Dowd,paul.odowd@bristol.ac.uk,,,Self-Organised Heterogenous Swarm Partitioning,"If the proposed benefits of swarm robotics hold true, we can imagine a future of thousands of cheap robots being deployed to solve our problems.  However, this would mean many swarms operating and existing within the same environments.  Swarms are understood to make extensive use of their interactions with the environment and other robots to coordinate their group-level behaviours.  As such, many swarms are likely to interfere with each otherâ€™s operation.   Therefore, it would be valuable and useful if many swarms could identify which swarm they belong to, and to organise themselves appropriately.  This goal is made a challenge because we attempt to avoid any centralised control or identifying attributes within swarm systems.  It is also the case that the algorithm to allow swarms to self-identify should itself be a self-organising and decentralised mechanism.   This study will investigate a probabilistic approach to allow individual swarm robots to develop a belief about which swarm they belong to based on the success of their interactions with other robots.   We can roughly imagine this as analogous to perceiving â€œbeing accepted or rejectedâ€ù by a swarm.  The project is likely to have a period of implementation and evaluation in simulation before it can be progressed to an implementation on real robots.  For real-robots, a swarm of Pololu 3Pi+ robot fitted with Infra-red communication are an available candidate. ",1,,"[""MSc Robotics"",""MSc Aerial Robotics""]",,UoB,,No
Chanelle Lee,c.l.lee@bristol.ac.uk,"multi-agent systems, decision making, swarm robotics",,Low-cost Multi-Robot Tracking System,"When multi-robot control architectures tested in simulation are transferred to physical robots there is often a discrepancy in behaviour known as the reality gap. Often the reality gap manifests as a drop in performance, meaning that to fully evaluate a control architecture it needs to be tested on physical robots. However, multi-robot testbeds are currently both expensive, can be hard to access and difficult to set up with requirements such as a static arena, motion capture and tracking systems and multiple robots. Thus, there is a need for multi-robot testbeds which are low cost, accessible with a short build time. In this project, we will first look at creating a multi-robot testbed using low cost hardware and open-source software alternatives. For example, rather than a motion capture system we could instead use a system using web-cameras, Open-CV and QR codes. We will then evaluate the testbed on metrics such as max number of robots and robot pose accuracy/precision. Finally, as an extension we could implement ways to compensate for tracking loss or a projected information overlay. This project would suit a student looking for a project focused on practical work. Familiarity with a computer vision libraries such as Open-CV would be useful. ",1,,"[""MSc Robotics"",""MSc Bio-Robotics""]",Paul O'Dowd,UoB,,No
Paul O'Dowd,paul.odowd@bristol.ac.uk,swarm robotics,,Cross-Talk: Examining Local Communication in Swarm Robotics,"Swarm robotics has the governing principles of decentralised control and self-organised behaviours.  It is believed that these governing principles are facilitated through several key mechanisms.  One key mechanism is a necessity for local-communication - that communication distance should be constrained to be local relative to the size of a swarm agent.  This mechanism has been adopted and implemented into many swarm models and swarm systems.   In this study, we will investigate the real-world complexities and performance of a local-communication implementation.  The findings will be used to improve future models and implementations of swarm robotics.  For example, a real world complexity is that we expect there to be a degree of signal-interference when many robots are transmitting messages to one-another asynchronously.  These issues are confounded when we consider that the robots are mobile, and the functionality of communication may depend on task and context.   This project will make a structured investigation of an Infra-red (IR) messaging technology for a swarm of Pololu 3Pi+ robots.  The platform will be quantitatively evaluated for performance across several operational parameters.  From this, recommendations for swarm implementations will be proposed and evaluated.",1,,"[""MSc Robotics"",""MSc Aerial Robotics""]",,UoB,,No
Paul O'Dowd,paul.odowd@bristol.ac.uk,swarm robotics,,Intention Recognition for Swarm Robotic Box Pushing,"Intention Recognition for Swarm Robotic Box Pushing Box pushing is a frequently explored area of multi-agent systems, multi-robot systems, swarm robotics, and other areas.  As a scenario, box-pushing has an analogy to collective foraging behaviours in the natural world, such as when many ants push or pull an object back to the nest. Developments in robotic box-pushing include various ways to model, plan, predict and coordinate box-pushing behaviour.   In swarm robotics, such deliberative techniques and explicit communication strategies are often avoided to ensure a decentralised and self-organising principle of operation.  However, planning and communication does not necessarily compromise decentralised control.  This project will investigate how these â€œhigher levelâ€ù robotic mechanisms can be implemented in self-organised and decentralised ways, to benefit a swarm robotic approach.  In particular, it is proposed that swarm robots should be able to explicitly communicate their intention when engaged in box-pushing behaviour, and the utility of this will be explored across multiple scenarios.  ",1,,"[""MSc Robotics"",""MSc Aerial Robotics""]",,UoB,,No
Paul O'Dowd,paul.odowd@bristol.ac.uk,"Swarm Robotics, Human Swarm Interaction, Machine Vision",,Attention Holding in Human-Swarm Interaction,"This project will use the new Mosaix Tile robotâ€™s designed by Merihan Alhafnawi.  These swarm robots are fitted with cameras that allow them to make high-resolution observations of the task environment.  This study will focus on the research are of human-swarm interaction (HSI).   In HSI, we wish to investigate how a human can hold meaningful interactions with a swarm, without compromising the core mechanisms of swarm robotic systems.  These include decentralised control and self-organisation.  Therefore, it is expected that a human would not necessarily make a direct communication to any one robot, or utilise any specific robot as a centralised node.  This raises the research question of how well a human can understand if they are communicating with a swarm (or not).  Does a human communicate with one robot, or the swarm as a whole?  How can a human know when they are interacting successfully with a whole swarm?   This project will utilise the camera of the Mosaix to implement face tracking.  The robots will therefore be able to individually perceive the presence and directed-gaze of a human.  The project will look to investigate and implement how a swarm can realise and collectively focus their attention on a human in a self-organised way.  The study will conduct multiple experiment scenarios to understand whether a human consequently believes they can capture and hold the meaningful attention of a swarm, and which swarm robotic mechanisms underpin this.",1,,"[""MSc Robotics""]",Merihan Alhafnawi,UoB,,No
Paul O'Dowd,paul.odowd@bristol.ac.uk,"Embodied AI, C, Java, Artificial Creativity",,Objectively Interesting Robotic Drawings,"Whilst it is possible to build various machines and robots to execute (produce) drawings, it is a much harder problem to decide what to draw.  This question of â€œwhat to drawâ€ù implicates intentionality â€“ when we draw, we start with an idea and attempt to complete it to our satisfaction.  This becomes a process of trial-and-error â€“ a search process - where we optimise our actions and adjust our expectations.   Furthermore, â€œhow to drawâ€ù is a second question that implicates reason â€“ when we make marks, we utilise the characteristics of the drawing materials to suggest or infer information about a subject we have observed â€“ for example, bold lines, hatching, or a wash of colour, all communicate different information.   If a person is asked to draw, â€œwhatâ€ù and â€œhowâ€ù will change depending on the experience of the materials they are given.  Existing research shows that this includes a broad range of senses, including auditory, tactile and visual perception.  This makes drawing a good candidate to research embodied artificial intelligence.   This project looks to take a small step towards a robot which can determine â€œwhatâ€ù and â€œhowâ€ù when drawing.  This project will use a load-cell sensor to allow a robot to perceive tactile information whilst drawing.  A heuristic search algorithm will be applied to generate drawing-actions, which will then be evaluated for the resultant tactile information produced.  An implementation of Shannonâ€™s Entropy measure of information (or similar) will allow for a correlation between action and information rendered.   The project will evaluate whether this computational understanding of information, combined with an optimisation of actions, is made apparent in the reality of robot drawings. Students in this project must be proficient in C, Java and be comfortable with kinematics.  The project will utilise an existing 6dof stewart platform built for robotic drawing.",1,,"[""MSc Robotics""]",,UoB,,No
Andrew Conn,a.conn@bristol.ac.uk,"Fish, Autonomous underwater vehicle, AUV, swimming",,Robotic fish,"Autonomous underwater vehicles (AUVs) are increasingly required for harbour monitoring, to inspect infrastructure for tidal energy harvesting and to track environmental factors such as marine pollution.  Fish-inspired robots have the potential to exploit the high hydrodynamic efficiencies of biological swimmers, but they are typically restricted by inefficient actuation and body form. This project aims to develop a fish-inspired robotic propulsion system that combines high hydrodynamic and electromechanical efficiencies.",1,,"[""MSc Bio-Robotics"",""MSc Robotics""]",Jonathan Rossiter,UoB,,No
Andrew Conn,a.conn@bristol.ac.uk,"soft robotics, embodied intelligence",,Embodied digital logic,"The principle of a transistor can be embodied as an electromechanical â€œswitchâ€ù that switches an electrical signal on and off in response to mechanical deformation. This will enable digital logic, and hence computation, to be driven by mechanical stimuli in the bodies of robots. By using soft robotic materials, the electromechanical switches could be flexible and fully integrated into the robotâ€™s body so that it can perform computation while interacting with its environment without the need for additional sensors and centralised control. This would create soft robotic systems that are more resistant to failure by removing the need for single processor (and point of failure). This project will focus on the design of a novel soft electromechanical switch that requires no additional circuitry to respond to mechanical stimuli such as force or strain, so that logic gates and other forms of computation can be embodied in a robotic prototype.",1,,"[""MSc Robotics""]",,UoB,,No
Shane Windsor,shane.windsor@bristol.ac.uk,"Trust, machine learning, MAV, quadcopter",,Trustworthy machine learning based agile flight control of quadcopters,Machine learning offers many potential advantages over conventional flight control algorithms but it is very challenging to verify these systems and to guarantee their robustness and performance as can be done with conventional control systems. This project will look at approaches for using machine learning as part of a flight control system in a way that allows robust performance to be guaranteed. The project would use the CrazyFly micro-quadcopter flying in the BRL flight arena as the test platform for this study.,1,,"[""MSc Aerial Robotics""]",,UoB,,No
Shane Windsor,shane.windsor@bristol.ac.uk,"Wind, soaring, UAV, city",,Bio-inspired soaring in urban environments,Birds save substantial amounts of energy by using the wind flows in urban environments to reduce their flight costs. This project will look at developing path planning algorithms which use the wind fields around buildings to save energy for fixed wing UAV flight.,1,,"[""MSc Aerial Robotics""]",,UoB,,No
Shane Windsor,shane.windsor@bristol.ac.uk,"Flow sensing, force sensing, UAV, flight test",,Bio-inspired distributed flow sensing,Birds and insects all have arrays of distributed force and flow sensors on their wings. We have developed fixed wing UAVs with similar arrays of sensors to explore how this type of information can be used as part of a flight control system. This project will look at conducting outdoor flight testing with this platform to characterise the signal properties available from this system and explore how these signals can be integrated into the flight control system.,,,"[""MSc Robotics""]",,UoB,,No
Helmut Hauser,helmut.hauser@bristol.ac.uk,"morphological computation, physical reservoir computing, soft robotics",,Design through Stimulation â€“ Designing Robot Morphologies through Mechano-stimulation of Stem Cells in Simulation,"Conventionally, robots are designed and assembled. However, this becomes non-trivial, even unfeasible, for smaller scale robots. This project will explore an alternative approach by obtaining robot morphologies through stimulation of stem cella. Specifically, we will exploit the mechano-sensitivity of stem cells that drives differentiation to new phenotypes with different morphological features, e.g., chondrocytes (â€œcartilageâ€ù), osteoblasts (â€œbonesâ€ù), via responses to different levels of mechanical stimulation. This provides a mechanism that translates mechanical stimulation into emergent morphological designs (i.e., level of force â†’ level of stiffness).  The idea will be explored in simluation. We will focus on a specific proof-of-concept, i.e., the tail for a tadpole inspired swimming robot, which will be exposed to water flow.  The level of mechanical stimulation and resulting strains will differ at different locations on the body. As a result, at different body parts we will obtain different cell expressions and, correspondingly, different levels of stiffness.  Requirements: Programming skills (e.g. Python)",1,,"[""MSc Bio-Robotics"",""MSc Robotics""]",,UoB,,No
,,,,,,194,,,,,,